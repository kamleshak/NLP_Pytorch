{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Yelp_Review_Classification",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKb3KfJgzpun"
      },
      "source": [
        "from torchtext.datasets import YelpReviewFull"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pXFnhhMzx4R",
        "outputId": "2a08da49-5787-4004-a839-eab0c631f049"
      },
      "source": [
        "# DBPedia dataset with 560000 train records with 14 classes.\n",
        "help(YelpReviewFull)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on function YelpReviewFull in module torchtext.datasets.yelpreviewfull:\n",
            "\n",
            "YelpReviewFull(root='.data', split=('train', 'test'))\n",
            "    YelpReviewFull dataset\n",
            "    \n",
            "    Separately returns the train/test split\n",
            "    \n",
            "    Number of lines per split:\n",
            "        train: 650000\n",
            "    \n",
            "        test: 50000\n",
            "    \n",
            "    \n",
            "    Number of classes\n",
            "        5\n",
            "    \n",
            "    \n",
            "    Args:\n",
            "        root: Directory where the datasets are saved.\n",
            "            Default: .data\n",
            "        split: split or splits to be returned. Can be a string or tuple of strings.\n",
            "            Default: ('train', 'test')\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3sWLqLmz2tp"
      },
      "source": [
        "train_iter = YelpReviewFull(split='train')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrB4PfQA0MQi",
        "outputId": "a960f836-dfb8-43b8-8843-eb20a973de35"
      },
      "source": [
        "# Check Samples of dataset from train iter.\n",
        "for (line_number, (label, line)) in enumerate(train_iter):\n",
        "    print(label, line)\n",
        "    if line_number == 20:\n",
        "        break"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5 dr. goldberg offers everything i look for in a general practitioner.  he's nice and easy to talk to without being patronizing; he's always on time in seeing his patients; he's affiliated with a top-notch hospital (nyu) which my parents have explained to me is very important in case something happens and you need surgery; and you can get referrals to see specialists without having to see him first.  really, what more do you need?  i'm sitting here trying to think of any complaints i have about him, but i'm really drawing a blank.\n",
            "2 Unfortunately, the frustration of being Dr. Goldberg's patient is a repeat of the experience I've had with so many other doctors in NYC -- good doctor, terrible staff.  It seems that his staff simply never answers the phone.  It usually takes 2 hours of repeated calling to get an answer.  Who has time for that or wants to deal with it?  I have run into this problem with many other doctors and I just don't get it.  You have office workers, you have patients with medical needs, why isn't anyone answering the phone?  It's incomprehensible and not work the aggravation.  It's with regret that I feel that I have to give Dr. Goldberg 2 stars.\n",
            "4 Been going to Dr. Goldberg for over 10 years. I think I was one of his 1st patients when he started at MHMG. He's been great over the years and is really all about the big picture. It is because of him, not my now former gyn Dr. Markoff, that I found out I have fibroids. He explores all options with you and is very patient and understanding. He doesn't judge and asks all the right questions. Very thorough and wants to be kept in the loop on every aspect of your medical health and your life.\n",
            "4 Got a letter in the mail last week that said Dr. Goldberg is moving to Arizona to take a new position there in June.  He will be missed very much.  \\n\\nI think finding a new doctor in NYC that you actually like might almost be as awful as trying to find a date!\n",
            "1 I don't know what Dr. Goldberg was like before  moving to Arizona, but let me tell you, STAY AWAY from this doctor and this office. I was going to Dr. Johnson before he left and Goldberg took over when Johnson left. He is not a caring doctor. He is only interested in the co-pay and having you come in for medication refills every month. He will not give refills and could less about patients's financial situations. Trying to get your 90 days mail away pharmacy prescriptions through this guy is a joke. And to make matters even worse, his office staff is incompetent. 90% of the time when you call the office, they'll put you through to a voice mail, that NO ONE ever answers or returns your call. Both my adult children and husband have decided to leave this practice after experiencing such frustration. The entire office has an attitude like they are doing you a favor. Give me a break! Stay away from this doc and the practice. You deserve better and they will not be there when you really need them. I have never felt compelled to write a bad review about anyone until I met this pathetic excuse for a doctor who is all about the money.\n",
            "5 Top notch doctor in a top notch practice. Can't say I am surprised when I was referred to him by another doctor who I think is wonderful and because he went to one of the best medical schools in the country. \\nIt is really easy to get an appointment. There is minimal wait to be seen and his bedside manner is great.\n",
            "5 Dr. Eric Goldberg is a fantastic doctor who has correctly diagnosed every issue that my wife and I have had. Unlike many of my past doctors, Dr. Goldberg is very accessible and we have been able to schedule appointments with him and his staff very quickly. We are happy to have him in the neighborhood and look forward to being his patients for many years to come.\n",
            "1 I'm writing this review to give you a heads up before you see this Doctor. The office staff and administration are very unprofessional. I left a message with multiple people regarding my bill, and no one ever called me back. I had to hound them to get an answer about my bill. \\n\\nSecond, and most important, make sure your insurance is going to cover Dr. Goldberg's visits and blood work. He recommended to me that I get a physical, and he knew I was a student because I told him. I got the physical done. Later, I found out my health insurance doesn't pay for preventative visits. I received an $800.00 bill for the blood work. I can't pay for my bill because I'm a student and don't have any cash flow at this current time. I can't believe the Doctor wouldn't give me a heads up to make sure my insurance would cover work that wasn't necessary and was strictly preventative. The office can't do anything to help me cover the bill. In addition, the office staff said the onus is on me to make sure my insurance covers visits. Frustrating situation!\n",
            "2 Wing sauce is like water. Pretty much a lot of butter and some hot sauce (franks red hot maybe).  The whole wings are good size and crispy, but for $1 a wing the sauce could be better. The hot and extra hot are about the same flavor/heat.  The fish sandwich is good and is a large portion, sides are decent.\n",
            "3 Decent range somewhat close to the city.  The mats are pretty solid; however, the grass range needs to be tended too.  It's like hitting out of US Open type rough...not very amenable to practicing.  Which kind of defeats the purpose of going to a golf range...Still gets 3 stars because the range is lit up at night which is excellent for those of us who are addicted to this amazing game, but are somewhat short on time (having a job kinda sucks sometimes, no?).\n",
            "1 Owning a driving range inside the city limits is like a license to print money.  I don't think I ask much out of a driving range.  Decent mats, clean balls and accessible hours.  Hell you need even less people now with the advent of the machine that doles out the balls.  This place has none of them.  It is april and there are no grass tees yet.  BTW they opened for the season this week although it has been golfing weather for a month.  The mats look like the carpet at my 107 year old aunt Irene's house.  Worn and thread bare.  Let's talk about the hours.  This place is equipped with lights yet they only sell buckets of balls until 730.  It is still light out.  Finally lets you have the pit to hit into.  When I arrived I wasn't sure if this was a driving range or an excavation site for a mastodon or a strip mining operation.  There is no grass on the range. Just mud.  Makes it a good tool to figure out how far you actually are hitting the ball.  Oh, they are cash only also.\\n\\nBottom line, this place sucks.  The best hope is that the owner sells it to someone that actually wants to make money and service golfers in Pittsburgh.\n",
            "1 This place is absolute garbage...  Half of the tees are not available, including all the grass tees.  It is cash only, and they sell the last bucket at 8, despite having lights.  And if you finish even a minute after 8, don't plan on getting a drink.  The vending machines are sold out (of course) and they sell drinks inside, but close the drawers at 8 on the dot.  There are weeds grown all over the place.  I noticed some sort of batting cage, but it looks like those are out of order as well.  Someone should buy this place and turn it into what it should be.\n",
            "4 I drove by yesterday to get a sneak peak.  It re-opens on July 14th and I can't wait to take my kids.  The new range looks amazing.  The entire range appears to be turf, which may or many not help your game, but it looks really nice.  The tee boxes look state of the art and the club house looks like something you'll see on a newer course.  Can't wait to experience it!\n",
            "2 After waiting for almost 30 minutes to trade in an old phone part of the buy back program, our customer service rep incorrectly processed the transaction. This led to us waiting another 30 minutes for him to correct it. Don't visit this store if you want pleasant or good service.\n",
            "5 This place was DELICIOUS!!  My parents saw a recommendation to visit this place from Rick Sebak's \\\"25 Things I Like About Pittsburgh\\\" and he's usually pretty accurate.  His recommendations were to try the Reuben, Fish Sandwich and Open-Faced Steak Sandwich.  We went early afternoon for a late lunch today (a Saturday) and were seated right away.  The staff is extremely friendly.  My Mom & I each had the fish sandwich, while my Dad & Brother had a Reuben sandwich.  The fish was very good, but the Reuben was to die for!  Both dishes were massive, and could very easily be shared between two people.  On top of being extremely large portions, it was incredibly affordable.  The giant fish sandwich was $8 and the giant Reuben was $7.50.  Our drinks were always filled and we were checked on several times during the meal.  We will definitely be back!!!  Oh and a bit of advice ahead of time - they take CASH ONLY.  So come prepared, but I'm pretty sure I saw an ATM there as well.  And I do believe they are closed on Sundays & Mondays.\n",
            "5 Can't miss stop for the best Fish Sandwich in Pittsburgh.\n",
            "5 This place should have a lot more reviews - but I'm glad it doesn't, they don't need to get any busier.\\n\\nIts been there ages, and looks it. If you're all about ambiance, don't bother. If you pretend you're in a movie set in Pittsburgh 30 years ago it works pretty well. The service is sometimes hit or miss. Most of girls are good, one is very slow, one is amazing. They are all friendly and usually a few different people will check in to make sure that you're happy. Everything is made fresh so be prepared that nothing comes flying out of that kitchen - busy times it can take a good while to get food. \\n\\nThe food is AWESOME! Worth any little complaints I might think up before it gets there. Once its on the table, I forget them all.\\n\\n-Fish Sandwiich\\n-Salmon (huge and delicious)\\n-Flounder\\n-Shrimp a few ways (\\\"Norfolk\\\" style is oily for my taste, and I never had it growing up in Norfolk.)\\n-Hawkins St Special\\n-Prime Rib (sized for two, watch it)\\n\\nThe prices are low, the portions are large, and just about everything on the menu  is delicious. I'm not one to pick a place because they give you a lot of food, but if you like a good value and don't want to compromise on taste, this place is a gem.\n",
            "5 Old school.....traditional \\\"mom 'n pop\\\" quality and perfection. The best fish and chips you'll ever enjoy and equally superb fried shrimp. A great out of the way, non-corporate, vestige of Americana. You will love it.\n",
            "5 Good fish sandwich.\n",
            "5 After a morning of Thrift Store hunting, a friend and I were thinking of lunch, and he suggested Emil's after he'd seen Chris Sebak do a bit on it and had tried it a time or two before, and I had not. He said they had a decent Reuben, but to be prepared to step back in time.\\n\\nWell, seeing as how I'm kind of addicted to late 40's and early 50's, and the whole Rat Pack scene, stepping back in time is a welcomed change in da burgh...as long as it doesn't involve 1979, which I can see all around me every day.\\n\\nAnd yet another shot at finding a decent Reuben in da burgh...well, that's like hunting the Holy Grail. So looking under one more bush certainly wouldn't hurt.\\n\\nSo off we go right at lunchtime in the middle of...where exactly were we? At first I thought we were lost, driving around a handful of very rather dismal looking blocks in what looked like a neighborhood that had been blighted by the building of a highway. And then...AHA! Here it is! And yep, there it was. This little unassuming building with an add-on entrance with what looked like a very old hand painted sign stating quite simply 'Emil's. \\n\\nWe walked in the front door, and entered another world. Another time, and another place. Oh, and any Big Burrito/Sousa foodies might as well stop reading now. I wouldn't want to see you walk in, roll your eyes and say 'Reaaaaaalllly?'\\n\\nThis is about as old world bar/lounge/restaurant as it gets. Plain, with a dark wood bar on one side, plain white walls with no yinzer pics, good sturdy chairs and actual white linens on the tables. This is the kind of neighborhood dive that I could see Frank and Dino pulling a few tables together for some poker, a fish sammich, and some cheap scotch. And THAT is exactly what I love.\\n\\nOh...but good food counts too. \\n\\nWe each had a Reuben, and my friend had a side of fries. The Reubens were decent, but not NY awesome. A little too thick on the bread, but overall, tasty and definitely filling. Not too skimpy on the meat. I seriously CRAVE a true, good NY Reuben, but since I can't afford to travel right now, what I find in da burgh will have to do. But as we sat and ate, burgers came out to an adjoining table. Those were some big thick burgers. A steak went past for the table behind us. That was HUGE! And when we asked about it, the waitress said 'Yeah, it's huge and really good, and he only charges $12.99 for it, ain't that nuts?' Another table of five came in, and wham. Fish sandwiches PILED with breaded fish that looked amazing. Yeah, I want that, that, that and THAT!\\n\\nMy friend also mentioned that they have a Chicken Parm special one day of the week that is only served UNTIL 4 pm, and that it is fantastic. If only I could GET there on that week day before 4...\\n\\nThe waitress did a good job, especially since there was quite a growing crowd at lunchtime on a Saturday, and only one of her. She kept up and was very friendly. \\n\\nThey only have Pepsi products, so I had a brewed iced tea, which was very fresh, and she did pop by to ask about refills as often as she could. As the lunch hour went on, they were getting busy.\\n\\nEmil's is no frills, good portions, very reasonable prices, VERY comfortable neighborhood hole in the wall...kind of like Cheers, but in a blue collar neighborhood in the 1950's. Fan-freakin-tastic! I could feel at home here.\\n\\nYou definitely want to hit Mapquest or plug in your GPS though. I am not sure that I could find it again on my own...it really is a hidden gem. I will be making my friend take me back until I can memorize where the heck it is.\\n\\nAddendum: 2nd visit for the fish sandwich. Excellent. Truly. A pound of fish on a fish-shaped bun (as opposed to da burgh's seemingly popular hamburger bun). The fish was flavorful, the batter excellent, and for just $8. This may have been the best fish sandwich I've yet to have in da burgh.\n",
            "4 A great townie bar with tasty food and an interesting clientele. I went to check this place out on the way home from the airport one Friday night and it didn't disappoint. It is refreshing to walk into a townie bar and not feel like the music stops and everyone in the place is staring at you - I'm guessing the mixed crowd of older hockey fans, young men in collared shirts, and thirtysomethings have probably seen it all during their time at this place. \\n\\nThe staff was top notch - the orders were somewhat overwhelming as they appeared short-staffed for the night, but my waitress tried to keep a positive attitude for my entire visit. The other waiter was wearing a hooded cardigan, and I wanted to steal it from him due to my difficulty in finding such a quality article of clothing.\\n\\nWe ordered a white pizza - large in size, engulfed in cheese, full of garlic flavor, flavorful hot sausage. An overall delicious pizza, aside from 2 things: 1, way too much grease (I know this comes with the territory, but still, it is sometimes unbearable); 2, CANNED MUSHROOMS - the worst thing to come out of a can. Ever. I would rather eat canned Alpo than canned mushrooms. And if the mushrooms weren't canned, they were just the worst mushrooms I've ever consumed. The mushroom debacle is enough to lower the review by an entire star - disgusting!\\n\\nMy advice for the place is keep everything awesome - random music from the jukebox, tasty food, great prices, good crowd and staff - and get some decent mushrooms; why they spoil an otherwise above average pie with such inferior crap, I'll never know.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7LwnrU-0cMI"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "train_iter = YelpReviewFull(split = 'train')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zq-IuEKY2GQR"
      },
      "source": [
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oALqqil43mX2"
      },
      "source": [
        "tokenizer = get_tokenizer(\"basic_english\")\n",
        "train_iter = YelpReviewFull(split = 'train')\n",
        "\n",
        "def yield_tokens(data_iter):\n",
        "    for _, text in data_iter:\n",
        "        yield tokenizer(text)\n",
        "\n",
        "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=[\"<unk>\"])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6Cp7Qbw6xS1"
      },
      "source": [
        "vocab.set_default_index(vocab[\"<unk>\"])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uK1sxfsM7doh"
      },
      "source": [
        "# pipelines\n",
        "text_pipeline = lambda x: vocab(tokenizer(x))\n",
        "# make sure to make it start from zero else it will give RuntimeError: CUDA error: device-side assert triggered\n",
        "label_pipeline = lambda x: int(x) - 1"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xArz2o1P8MKG"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def collate_fn(batch):\n",
        "    src_batch = []\n",
        "    for src_batch in batch:\n",
        "        src_batch.append(text_transform[SRC_LANGUAGE](src_sample.rstrip('\\n')))\n",
        "    \n",
        "    src_batch = pad_sequences(src_batch, padding_value=PAD_IDX)\n",
        "  \n",
        "    return src_batch"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSeLl_Sh-6ON"
      },
      "source": [
        "def collate_batch(batch):\n",
        "    label_list, text_list, offsets = [], [], [0]\n",
        "    for (_label, _text) in batch:\n",
        "         label_list.append(label_pipeline(_label))\n",
        "         processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
        "         text_list.append(processed_text)\n",
        "         offsets.append(processed_text.size(0))\n",
        "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
        "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
        "    text_list = torch.cat(text_list)\n",
        "    return label_list.to(device), text_list.to(device), offsets.to(device)    "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRDpOkXiAqyo"
      },
      "source": [
        "train_iter = YelpReviewFull(split='train')\n",
        "dataloader = DataLoader(train_iter, batch_size=8, shuffle=False, collate_fn=collate_batch)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-IOBmF7A1N-"
      },
      "source": [
        "from torch import nn\n",
        "\n",
        "class TextClassificationModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embed_dim, num_class):\n",
        "        super(TextClassificationModel, self).__init__()\n",
        "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
        "        self.fc = nn.Linear(embed_dim, num_class)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.5\n",
        "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.bias.data.zero_()\n",
        "\n",
        "    def forward(self, text, offsets):\n",
        "        embedded = self.embedding(text, offsets)\n",
        "        return self.fc(embedded)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cW1rS0OYBGhR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b81016cb-b7aa-44d2-ea5a-6281cac8e3dc"
      },
      "source": [
        "train_iter = YelpReviewFull(split='train')\n",
        "num_class = len(set([label for (label, text) in train_iter]))\n",
        "print(num_class)\n",
        "vocab_size = len(vocab)\n",
        "emsize = 64\n",
        "model = TextClassificationModel(vocab_size, emsize, num_class).to(device)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtVCypgvBQfM"
      },
      "source": [
        "import time\n",
        "\n",
        "def train(dataloader):\n",
        "    model.train()\n",
        "    total_acc, total_count = 0, 0\n",
        "    log_interval = 500\n",
        "    start_time = time.time()\n",
        "\n",
        "    for idx, (label, text, offsets) in enumerate(dataloader):\n",
        "        optimizer.zero_grad()\n",
        "        predited_label = model(text, offsets)\n",
        "        loss = criterion(predited_label, label)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1) # disuccees\n",
        "        optimizer.step()\n",
        "        total_acc += (predited_label.argmax(1) == label).sum().item()\n",
        "        total_count += label.size(0)\n",
        "        if idx % log_interval == 0 and idx > 0:\n",
        "            elapsed = time.time() - start_time\n",
        "            print('| epoch {:3d} | {:5d}/{:5d} batches '\n",
        "                  '| accuracy {:8.3f}'.format(epoch, idx, len(dataloader),\n",
        "                                              total_acc/total_count))\n",
        "            total_acc, total_count = 0, 0\n",
        "            start_time = time.time()\n",
        "\n",
        "def evaluate(dataloader):\n",
        "    model.eval()\n",
        "    total_acc, total_count = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, (label, text, offsets) in enumerate(dataloader):\n",
        "            predited_label = model(text, offsets)\n",
        "            loss = criterion(predited_label, label)\n",
        "            total_acc += (predited_label.argmax(1) == label).sum().item()\n",
        "            total_count += label.size(0)\n",
        "    return total_acc/total_count"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eV7lPedpBfpS",
        "outputId": "fc99abb5-db54-4126-9a5d-b041dcfbea24"
      },
      "source": [
        "from torch.utils.data.dataset import random_split\n",
        "from torchtext.data.functional import to_map_style_dataset\n",
        "# Hyperparameters\n",
        "EPOCHS = 10 # epoch\n",
        "LR = 5  # learning rate\n",
        "BATCH_SIZE = 64 # batch size for training\n",
        "  \n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
        "total_accu = None\n",
        "train_iter, test_iter = YelpReviewFull()\n",
        "train_dataset = to_map_style_dataset(train_iter)\n",
        "test_dataset = to_map_style_dataset(test_iter)\n",
        "num_train = int(len(train_dataset) * 0.95)\n",
        "split_train_, split_valid_ = \\\n",
        "    random_split(train_dataset, [num_train, len(train_dataset) - num_train])\n",
        "\n",
        "train_dataloader = DataLoader(split_train_, batch_size=BATCH_SIZE,\n",
        "                              shuffle=True, collate_fn=collate_batch)\n",
        "valid_dataloader = DataLoader(split_valid_, batch_size=BATCH_SIZE,\n",
        "                              shuffle=True, collate_fn=collate_batch)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n",
        "                             shuffle=True, collate_fn=collate_batch)\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    epoch_start_time = time.time()\n",
        "    train(train_dataloader)\n",
        "    accu_val = evaluate(valid_dataloader)\n",
        "    if total_accu is not None and total_accu > accu_val:\n",
        "        scheduler.step()\n",
        "    else:\n",
        "        total_accu = accu_val\n",
        "    print('-' * 59)\n",
        "    print('| end of epoch {:3d} | time: {:5.2f}s | '\n",
        "          'valid accuracy {:8.3f} '.format(epoch,\n",
        "                                           time.time() - epoch_start_time,\n",
        "                                           accu_val))\n",
        "    print('-' * 59)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   1 |   500/ 9649 batches | accuracy    0.379\n",
            "| epoch   1 |  1000/ 9649 batches | accuracy    0.485\n",
            "| epoch   1 |  1500/ 9649 batches | accuracy    0.512\n",
            "| epoch   1 |  2000/ 9649 batches | accuracy    0.526\n",
            "| epoch   1 |  2500/ 9649 batches | accuracy    0.539\n",
            "| epoch   1 |  3000/ 9649 batches | accuracy    0.544\n",
            "| epoch   1 |  3500/ 9649 batches | accuracy    0.543\n",
            "| epoch   1 |  4000/ 9649 batches | accuracy    0.550\n",
            "| epoch   1 |  4500/ 9649 batches | accuracy    0.555\n",
            "| epoch   1 |  5000/ 9649 batches | accuracy    0.557\n",
            "| epoch   1 |  5500/ 9649 batches | accuracy    0.560\n",
            "| epoch   1 |  6000/ 9649 batches | accuracy    0.563\n",
            "| epoch   1 |  6500/ 9649 batches | accuracy    0.563\n",
            "| epoch   1 |  7000/ 9649 batches | accuracy    0.561\n",
            "| epoch   1 |  7500/ 9649 batches | accuracy    0.563\n",
            "| epoch   1 |  8000/ 9649 batches | accuracy    0.567\n",
            "| epoch   1 |  8500/ 9649 batches | accuracy    0.569\n",
            "| epoch   1 |  9000/ 9649 batches | accuracy    0.566\n",
            "| epoch   1 |  9500/ 9649 batches | accuracy    0.567\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   1 | time: 96.96s | valid accuracy    0.579 \n",
            "-----------------------------------------------------------\n",
            "| epoch   2 |   500/ 9649 batches | accuracy    0.574\n",
            "| epoch   2 |  1000/ 9649 batches | accuracy    0.575\n",
            "| epoch   2 |  1500/ 9649 batches | accuracy    0.575\n",
            "| epoch   2 |  2000/ 9649 batches | accuracy    0.571\n",
            "| epoch   2 |  2500/ 9649 batches | accuracy    0.575\n",
            "| epoch   2 |  3000/ 9649 batches | accuracy    0.578\n",
            "| epoch   2 |  3500/ 9649 batches | accuracy    0.578\n",
            "| epoch   2 |  4000/ 9649 batches | accuracy    0.573\n",
            "| epoch   2 |  4500/ 9649 batches | accuracy    0.575\n",
            "| epoch   2 |  5000/ 9649 batches | accuracy    0.577\n",
            "| epoch   2 |  5500/ 9649 batches | accuracy    0.579\n",
            "| epoch   2 |  6000/ 9649 batches | accuracy    0.578\n",
            "| epoch   2 |  6500/ 9649 batches | accuracy    0.580\n",
            "| epoch   2 |  7000/ 9649 batches | accuracy    0.584\n",
            "| epoch   2 |  7500/ 9649 batches | accuracy    0.579\n",
            "| epoch   2 |  8000/ 9649 batches | accuracy    0.579\n",
            "| epoch   2 |  8500/ 9649 batches | accuracy    0.579\n",
            "| epoch   2 |  9000/ 9649 batches | accuracy    0.581\n",
            "| epoch   2 |  9500/ 9649 batches | accuracy    0.583\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   2 | time: 96.43s | valid accuracy    0.582 \n",
            "-----------------------------------------------------------\n",
            "| epoch   3 |   500/ 9649 batches | accuracy    0.582\n",
            "| epoch   3 |  1000/ 9649 batches | accuracy    0.579\n",
            "| epoch   3 |  1500/ 9649 batches | accuracy    0.589\n",
            "| epoch   3 |  2000/ 9649 batches | accuracy    0.579\n",
            "| epoch   3 |  2500/ 9649 batches | accuracy    0.585\n",
            "| epoch   3 |  3000/ 9649 batches | accuracy    0.581\n",
            "| epoch   3 |  3500/ 9649 batches | accuracy    0.584\n",
            "| epoch   3 |  4000/ 9649 batches | accuracy    0.585\n",
            "| epoch   3 |  4500/ 9649 batches | accuracy    0.586\n",
            "| epoch   3 |  5000/ 9649 batches | accuracy    0.589\n",
            "| epoch   3 |  5500/ 9649 batches | accuracy    0.585\n",
            "| epoch   3 |  6000/ 9649 batches | accuracy    0.584\n",
            "| epoch   3 |  6500/ 9649 batches | accuracy    0.585\n",
            "| epoch   3 |  7000/ 9649 batches | accuracy    0.586\n",
            "| epoch   3 |  7500/ 9649 batches | accuracy    0.584\n",
            "| epoch   3 |  8000/ 9649 batches | accuracy    0.586\n",
            "| epoch   3 |  8500/ 9649 batches | accuracy    0.585\n",
            "| epoch   3 |  9000/ 9649 batches | accuracy    0.585\n",
            "| epoch   3 |  9500/ 9649 batches | accuracy    0.589\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   3 | time: 97.47s | valid accuracy    0.598 \n",
            "-----------------------------------------------------------\n",
            "| epoch   4 |   500/ 9649 batches | accuracy    0.589\n",
            "| epoch   4 |  1000/ 9649 batches | accuracy    0.592\n",
            "| epoch   4 |  1500/ 9649 batches | accuracy    0.590\n",
            "| epoch   4 |  2000/ 9649 batches | accuracy    0.590\n",
            "| epoch   4 |  2500/ 9649 batches | accuracy    0.588\n",
            "| epoch   4 |  3000/ 9649 batches | accuracy    0.590\n",
            "| epoch   4 |  3500/ 9649 batches | accuracy    0.587\n",
            "| epoch   4 |  4000/ 9649 batches | accuracy    0.587\n",
            "| epoch   4 |  4500/ 9649 batches | accuracy    0.591\n",
            "| epoch   4 |  5000/ 9649 batches | accuracy    0.588\n",
            "| epoch   4 |  5500/ 9649 batches | accuracy    0.591\n",
            "| epoch   4 |  6000/ 9649 batches | accuracy    0.593\n",
            "| epoch   4 |  6500/ 9649 batches | accuracy    0.587\n",
            "| epoch   4 |  7000/ 9649 batches | accuracy    0.594\n",
            "| epoch   4 |  7500/ 9649 batches | accuracy    0.590\n",
            "| epoch   4 |  8000/ 9649 batches | accuracy    0.589\n",
            "| epoch   4 |  8500/ 9649 batches | accuracy    0.586\n",
            "| epoch   4 |  9000/ 9649 batches | accuracy    0.592\n",
            "| epoch   4 |  9500/ 9649 batches | accuracy    0.597\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   4 | time: 97.15s | valid accuracy    0.587 \n",
            "-----------------------------------------------------------\n",
            "| epoch   5 |   500/ 9649 batches | accuracy    0.606\n",
            "| epoch   5 |  1000/ 9649 batches | accuracy    0.609\n",
            "| epoch   5 |  1500/ 9649 batches | accuracy    0.607\n",
            "| epoch   5 |  2000/ 9649 batches | accuracy    0.610\n",
            "| epoch   5 |  2500/ 9649 batches | accuracy    0.605\n",
            "| epoch   5 |  3000/ 9649 batches | accuracy    0.607\n",
            "| epoch   5 |  3500/ 9649 batches | accuracy    0.610\n",
            "| epoch   5 |  4000/ 9649 batches | accuracy    0.612\n",
            "| epoch   5 |  4500/ 9649 batches | accuracy    0.608\n",
            "| epoch   5 |  5000/ 9649 batches | accuracy    0.612\n",
            "| epoch   5 |  5500/ 9649 batches | accuracy    0.609\n",
            "| epoch   5 |  6000/ 9649 batches | accuracy    0.605\n",
            "| epoch   5 |  6500/ 9649 batches | accuracy    0.609\n",
            "| epoch   5 |  7000/ 9649 batches | accuracy    0.613\n",
            "| epoch   5 |  7500/ 9649 batches | accuracy    0.611\n",
            "| epoch   5 |  8000/ 9649 batches | accuracy    0.609\n",
            "| epoch   5 |  8500/ 9649 batches | accuracy    0.607\n",
            "| epoch   5 |  9000/ 9649 batches | accuracy    0.615\n",
            "| epoch   5 |  9500/ 9649 batches | accuracy    0.606\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   5 | time: 98.49s | valid accuracy    0.604 \n",
            "-----------------------------------------------------------\n",
            "| epoch   6 |   500/ 9649 batches | accuracy    0.615\n",
            "| epoch   6 |  1000/ 9649 batches | accuracy    0.612\n",
            "| epoch   6 |  1500/ 9649 batches | accuracy    0.612\n",
            "| epoch   6 |  2000/ 9649 batches | accuracy    0.610\n",
            "| epoch   6 |  2500/ 9649 batches | accuracy    0.609\n",
            "| epoch   6 |  3000/ 9649 batches | accuracy    0.611\n",
            "| epoch   6 |  3500/ 9649 batches | accuracy    0.611\n",
            "| epoch   6 |  4000/ 9649 batches | accuracy    0.617\n",
            "| epoch   6 |  4500/ 9649 batches | accuracy    0.611\n",
            "| epoch   6 |  5000/ 9649 batches | accuracy    0.612\n",
            "| epoch   6 |  5500/ 9649 batches | accuracy    0.609\n",
            "| epoch   6 |  6000/ 9649 batches | accuracy    0.606\n",
            "| epoch   6 |  6500/ 9649 batches | accuracy    0.607\n",
            "| epoch   6 |  7000/ 9649 batches | accuracy    0.615\n",
            "| epoch   6 |  7500/ 9649 batches | accuracy    0.609\n",
            "| epoch   6 |  8000/ 9649 batches | accuracy    0.614\n",
            "| epoch   6 |  8500/ 9649 batches | accuracy    0.609\n",
            "| epoch   6 |  9000/ 9649 batches | accuracy    0.610\n",
            "| epoch   6 |  9500/ 9649 batches | accuracy    0.608\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   6 | time: 97.36s | valid accuracy    0.604 \n",
            "-----------------------------------------------------------\n",
            "| epoch   7 |   500/ 9649 batches | accuracy    0.610\n",
            "| epoch   7 |  1000/ 9649 batches | accuracy    0.611\n",
            "| epoch   7 |  1500/ 9649 batches | accuracy    0.611\n",
            "| epoch   7 |  2000/ 9649 batches | accuracy    0.613\n",
            "| epoch   7 |  2500/ 9649 batches | accuracy    0.609\n",
            "| epoch   7 |  3000/ 9649 batches | accuracy    0.617\n",
            "| epoch   7 |  3500/ 9649 batches | accuracy    0.609\n",
            "| epoch   7 |  4000/ 9649 batches | accuracy    0.610\n",
            "| epoch   7 |  4500/ 9649 batches | accuracy    0.608\n",
            "| epoch   7 |  5000/ 9649 batches | accuracy    0.611\n",
            "| epoch   7 |  5500/ 9649 batches | accuracy    0.609\n",
            "| epoch   7 |  6000/ 9649 batches | accuracy    0.616\n",
            "| epoch   7 |  6500/ 9649 batches | accuracy    0.611\n",
            "| epoch   7 |  7000/ 9649 batches | accuracy    0.609\n",
            "| epoch   7 |  7500/ 9649 batches | accuracy    0.610\n",
            "| epoch   7 |  8000/ 9649 batches | accuracy    0.615\n",
            "| epoch   7 |  8500/ 9649 batches | accuracy    0.612\n",
            "| epoch   7 |  9000/ 9649 batches | accuracy    0.609\n",
            "| epoch   7 |  9500/ 9649 batches | accuracy    0.608\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   7 | time: 100.78s | valid accuracy    0.606 \n",
            "-----------------------------------------------------------\n",
            "| epoch   8 |   500/ 9649 batches | accuracy    0.610\n",
            "| epoch   8 |  1000/ 9649 batches | accuracy    0.610\n",
            "| epoch   8 |  1500/ 9649 batches | accuracy    0.614\n",
            "| epoch   8 |  2000/ 9649 batches | accuracy    0.611\n",
            "| epoch   8 |  2500/ 9649 batches | accuracy    0.613\n",
            "| epoch   8 |  3000/ 9649 batches | accuracy    0.612\n",
            "| epoch   8 |  3500/ 9649 batches | accuracy    0.609\n",
            "| epoch   8 |  4000/ 9649 batches | accuracy    0.615\n",
            "| epoch   8 |  4500/ 9649 batches | accuracy    0.608\n",
            "| epoch   8 |  5000/ 9649 batches | accuracy    0.615\n",
            "| epoch   8 |  5500/ 9649 batches | accuracy    0.610\n",
            "| epoch   8 |  6000/ 9649 batches | accuracy    0.607\n",
            "| epoch   8 |  6500/ 9649 batches | accuracy    0.613\n",
            "| epoch   8 |  7000/ 9649 batches | accuracy    0.613\n",
            "| epoch   8 |  7500/ 9649 batches | accuracy    0.611\n",
            "| epoch   8 |  8000/ 9649 batches | accuracy    0.610\n",
            "| epoch   8 |  8500/ 9649 batches | accuracy    0.614\n",
            "| epoch   8 |  9000/ 9649 batches | accuracy    0.609\n",
            "| epoch   8 |  9500/ 9649 batches | accuracy    0.610\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   8 | time: 100.38s | valid accuracy    0.607 \n",
            "-----------------------------------------------------------\n",
            "| epoch   9 |   500/ 9649 batches | accuracy    0.614\n",
            "| epoch   9 |  1000/ 9649 batches | accuracy    0.615\n",
            "| epoch   9 |  1500/ 9649 batches | accuracy    0.612\n",
            "| epoch   9 |  2000/ 9649 batches | accuracy    0.613\n",
            "| epoch   9 |  2500/ 9649 batches | accuracy    0.614\n",
            "| epoch   9 |  3000/ 9649 batches | accuracy    0.611\n",
            "| epoch   9 |  3500/ 9649 batches | accuracy    0.613\n",
            "| epoch   9 |  4000/ 9649 batches | accuracy    0.607\n",
            "| epoch   9 |  4500/ 9649 batches | accuracy    0.614\n",
            "| epoch   9 |  5000/ 9649 batches | accuracy    0.614\n",
            "| epoch   9 |  5500/ 9649 batches | accuracy    0.609\n",
            "| epoch   9 |  6000/ 9649 batches | accuracy    0.610\n",
            "| epoch   9 |  6500/ 9649 batches | accuracy    0.613\n",
            "| epoch   9 |  7000/ 9649 batches | accuracy    0.613\n",
            "| epoch   9 |  7500/ 9649 batches | accuracy    0.615\n",
            "| epoch   9 |  8000/ 9649 batches | accuracy    0.612\n",
            "| epoch   9 |  8500/ 9649 batches | accuracy    0.616\n",
            "| epoch   9 |  9000/ 9649 batches | accuracy    0.611\n",
            "| epoch   9 |  9500/ 9649 batches | accuracy    0.613\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   9 | time: 97.29s | valid accuracy    0.608 \n",
            "-----------------------------------------------------------\n",
            "| epoch  10 |   500/ 9649 batches | accuracy    0.611\n",
            "| epoch  10 |  1000/ 9649 batches | accuracy    0.618\n",
            "| epoch  10 |  1500/ 9649 batches | accuracy    0.610\n",
            "| epoch  10 |  2000/ 9649 batches | accuracy    0.609\n",
            "| epoch  10 |  2500/ 9649 batches | accuracy    0.614\n",
            "| epoch  10 |  3000/ 9649 batches | accuracy    0.615\n",
            "| epoch  10 |  3500/ 9649 batches | accuracy    0.610\n",
            "| epoch  10 |  4000/ 9649 batches | accuracy    0.616\n",
            "| epoch  10 |  4500/ 9649 batches | accuracy    0.614\n",
            "| epoch  10 |  5000/ 9649 batches | accuracy    0.608\n",
            "| epoch  10 |  5500/ 9649 batches | accuracy    0.612\n",
            "| epoch  10 |  6000/ 9649 batches | accuracy    0.617\n",
            "| epoch  10 |  6500/ 9649 batches | accuracy    0.616\n",
            "| epoch  10 |  7000/ 9649 batches | accuracy    0.613\n",
            "| epoch  10 |  7500/ 9649 batches | accuracy    0.615\n",
            "| epoch  10 |  8000/ 9649 batches | accuracy    0.616\n",
            "| epoch  10 |  8500/ 9649 batches | accuracy    0.613\n",
            "| epoch  10 |  9000/ 9649 batches | accuracy    0.609\n",
            "| epoch  10 |  9500/ 9649 batches | accuracy    0.611\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  10 | time: 96.73s | valid accuracy    0.605 \n",
            "-----------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUrnPMhVBlq9",
        "outputId": "ddab14b3-4ba2-41a9-c943-87f1cb401788"
      },
      "source": [
        "print('Checking the results of test dataset.')\n",
        "accu_test = evaluate(test_dataloader)\n",
        "print('test accuracy {:8.3f}'.format(accu_test))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking the results of test dataset.\n",
            "test accuracy    0.600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76PGhuKbB4BN",
        "outputId": "840e4862-03aa-465e-a56b-713c30c52e7e"
      },
      "source": [
        "def predict(text, text_pipeline):\n",
        "    with torch.no_grad():\n",
        "        text = torch.tensor(text_pipeline(text))\n",
        "        output = model(text, torch.tensor([0]))\n",
        "        return output.argmax(1).item() + 1\n",
        "\n",
        "ex_text_str = '''Been going to Dr. Goldberg for over 10 years. I think I was one of his 1st patients when he started at MHMG. He's been great over the years and is really all about the big picture. It is because of him, not my now former gyn Dr. Markoff, that I found out I have fibroids. He explores all options with you and is very patient and understanding. He doesn't judge and asks all the right questions. Very thorough and wants to be kept in the loop on every aspect of your medical health and your life.'''\n",
        "\n",
        "model = model.to(\"cpu\")\n",
        "\n",
        "print(f\"Review rating is : {predict(ex_text_str, text_pipeline)}\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review rating is : 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yynf_myzJmlQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}