{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Pytorch_number_image_classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQcO_oSeL6bN"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.datasets as datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GC4uQ01-L6bW",
        "outputId": "5c2fbbe8-2eb6-4536-e3c9-78a9348c9d7a"
      },
      "source": [
        "mnist = datasets.MNIST(root='./data', download=True, transform=None)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5qamPR8L6bY",
        "outputId": "2ae28de4-ed29-473b-f8e6-52b4c6f347a3"
      },
      "source": [
        "len(mnist)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7IXcLQEL6bZ",
        "outputId": "f4a08f4f-9d04-4a40-ebc8-071ae2cb08a7"
      },
      "source": [
        "mnist[0]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<PIL.Image.Image image mode=L size=28x28 at 0x7FCA11A55790>, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByAFCtMHL6bb"
      },
      "source": [
        "# Plotting the images for mnist datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "rKXatenvL6bf",
        "outputId": "2d18e880-08a9-44bf-de4d-63d892fed314"
      },
      "source": [
        "figure = plt.figure(figsize=(8, 8))\n",
        "cols, rows = 3, 3\n",
        "for i in range(1, cols * rows + 1):\n",
        "    sample_idx = torch.randint(len(mnist), size=(1,)).item()\n",
        "    img, label = mnist[sample_idx]\n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    plt.title(f'label={label}')\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(img, cmap=\"gray\")\n",
        "plt.show()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 9 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xgBbrfHL6bh"
      },
      "source": [
        "## Generating second dataset of random numbers from 0 to 9\n",
        "Curently considering length of dataset same as that of length of mnist dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1NID51_L6bi",
        "outputId": "dee6a470-c488-4739-8c68-5ba4885418c0"
      },
      "source": [
        "num = np.random.randint(low=0, high=10, size=len(mnist))\n",
        "X1 = np.zeros((num.size, num.max()+1))\n",
        "X1 [np.arange(num.size),num] = 1\n",
        "print(f\"Printing the output labels: {num}\")\n",
        "print(f\"Printing the onehot encoded numbers Input: {X1}\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Printing the output labels: [1 2 0 ... 3 3 6]\n",
            "Printing the onehot encoded numbers Input: [[0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-C9C1qgwLKr"
      },
      "source": [
        "## Generating the Dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TX1Y40JkL6bk"
      },
      "source": [
        "class Dataset_prep(Dataset):\n",
        "    \n",
        "    # reading the image from mnist and taking random int.\n",
        "    def __init__(self, X1, num, mnist):\n",
        "        self.X1 = X1\n",
        "        self.mnist = mnist\n",
        "        self.num = num\n",
        "    \n",
        "    # number of rows in dataset [Considering length of mnist right now]\n",
        "    def __len__(self):\n",
        "        return len(self.num)\n",
        "    \n",
        "    # get image, its label, num, and added number.\n",
        "    def __getitem__(self, index):\n",
        "        image = ToTensor()(self.mnist[index][0]) # Transforming to tensor\n",
        "        number = torch.from_numpy(self.X1[index])\n",
        "        label1 = torch.tensor([self.mnist[index][1]])\n",
        "        label2 = self.num[index]\n",
        "        # Added number label\n",
        "        label2 = label2 + self.mnist[index][1]\n",
        "        label2 = torch.tensor([label2])\n",
        "\n",
        "        return {'image':image,'number':number,'label1':label1,'label2':label2}"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GW1dym8eFfA8"
      },
      "source": [
        "dataset = Dataset_prep(X1, num, mnist)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0MweLikP_Q1",
        "outputId": "934c520a-620f-4c8e-8acc-34374e81f749"
      },
      "source": [
        "len(dataset)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7u-tIVjBRjS9"
      },
      "source": [
        "batch = iter(dataset)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgUP61SkFnkV",
        "outputId": "b196e178-21a0-451e-fedc-7e6e7f60ceca"
      },
      "source": [
        "datadict = next(batch)\n",
        "print(datadict['label1'])\n",
        "print(datadict['label2'])\n",
        "print(datadict['number'].shape)\n",
        "print(datadict['image'].shape)\n",
        "datadict2 = next(batch)\n",
        "print(datadict2['label1'])\n",
        "print(datadict2['label2'])\n",
        "print(datadict2['number'].shape)\n",
        "print(datadict2['image'].shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([5])\n",
            "tensor([6])\n",
            "torch.Size([10])\n",
            "torch.Size([1, 28, 28])\n",
            "tensor([0])\n",
            "tensor([2])\n",
            "torch.Size([10])\n",
            "torch.Size([1, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaSyJxQRL6bl"
      },
      "source": [
        "# Train and Validation set\n",
        "train_set, val_set = torch.utils.data.random_split(dataset, [50000, 10000])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4aYeGDDL6bm"
      },
      "source": [
        "# Data Loader\n",
        "train_dataloader = DataLoader(train_set.dataset, batch_size=64, shuffle=True)\n",
        "test_dataloader = DataLoader(val_set.dataset, batch_size=64, shuffle=True)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KM5J_Rics5q",
        "outputId": "1929cd09-582b-4541-de8e-643bc71f93f8"
      },
      "source": [
        "dir(train_dataloader)\n",
        "train_dataloader.dataset[0]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'image': tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706,\n",
              "           0.4941, 0.5333, 0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.1176, 0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922,\n",
              "           0.9922, 0.9922, 0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922,\n",
              "           0.9333, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
              "           0.9922, 0.9843, 0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706,\n",
              "           0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137,\n",
              "           0.9686, 0.9451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.3137, 0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000,\n",
              "           0.1686, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275,\n",
              "           0.4235, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922,\n",
              "           0.9922, 0.4667, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294,\n",
              "           0.9922, 0.9922, 0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n",
              "           0.3647, 0.9882, 0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.9765, 0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098,\n",
              "           0.7176, 0.9922, 0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922,\n",
              "           0.9922, 0.9922, 0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922,\n",
              "           0.9922, 0.7882, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0902, 0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765,\n",
              "           0.3176, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706,\n",
              "           0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922,\n",
              "           0.9922, 0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922,\n",
              "           0.8314, 0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000]]]),\n",
              " 'label1': tensor([5]),\n",
              " 'label2': tensor([6]),\n",
              " 'number': tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=torch.float64)}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lv-NScPcwt3Q"
      },
      "source": [
        "## Creating the nnet model class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvRcOXrjL6bn"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        \n",
        "        # Input for Image: CNN based\n",
        "        self.conv1 = nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2)\n",
        "        self.FC11 = nn.Linear(32*7*7, 64)\n",
        "          \n",
        "        #Input for Model\n",
        "        self.layer_1 = nn.Linear(10, 32)\n",
        "        self.layer_2 = nn.Linear(32, 64)\n",
        "        self.layer_3 = nn.Linear(64, 128)\n",
        "        self.layer_4 = nn.Linear(128, 64)\n",
        "        \n",
        "        self.out2 = nn.Linear(128, 19) # it will have addition from 0 to 18 so 19\n",
        "        self.out1 = nn.Linear(128, 10) # It will have 10 classes from 0-9 and concatinated layer of 128\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = x1.reshape(-1, 1, 28, 28)\n",
        "        x1 = F.max_pool2d(F.relu(self.conv1(x1)),(2,2))\n",
        "        x1 = F.max_pool2d(F.relu(self.conv2(x1)),(2,2))\n",
        "        # print(f'x1.shape_after_conv:{x1.shape}')\n",
        "        x1 = x1.reshape(-1, 32*7*7)\n",
        "        # print(f'new: {x1.shape}')\n",
        "        x1 = self.FC11(x1)\n",
        "        # print(f'newfc: {x1.shape}')\n",
        "        # x2 = x2.view(-1, x2.size(0)).float()\n",
        "        x2 = x2.reshape(1, 10)\n",
        "        # print(f'x2: {x2.shape}')\n",
        "        x2 = F.relu(self.layer_1(x2.float()))\n",
        "        # print(f'x2.shape{x2.shape}')\n",
        "        x2 = F.relu(self.layer_2(x2))\n",
        "        # print(f'x2.shape{x2.shape}')\n",
        "        x2 = F.relu(self.layer_3(x2))\n",
        "        x2 = F.relu(self.layer_4(x2))\n",
        "        # Concatinating the fc layers of mnist and number\n",
        "        x = torch.cat((x1, x2), dim=1)\n",
        "        # print(f'x: {x.shape}')\n",
        "        out1 = self.out1(x)\n",
        "        out2 = self.out2(x)\n",
        "      \n",
        "        return {'label1':out1, 'label2':out2}\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3jyEIULL6bo",
        "outputId": "531f91c4-847f-4b63-ead3-a8d8e88e8e53"
      },
      "source": [
        "model = Model()\n",
        "opt = optim.SGD(model.parameters(), lr=10E-3)\n",
        "\n",
        "print(model)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model(\n",
            "  (conv1): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "  (conv2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "  (FC11): Linear(in_features=1568, out_features=64, bias=True)\n",
            "  (layer_1): Linear(in_features=10, out_features=32, bias=True)\n",
            "  (layer_2): Linear(in_features=32, out_features=64, bias=True)\n",
            "  (layer_3): Linear(in_features=64, out_features=128, bias=True)\n",
            "  (layer_4): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (out2): Linear(in_features=128, out_features=19, bias=True)\n",
            "  (out1): Linear(in_features=128, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XhdkJd9L6bp"
      },
      "source": [
        "criterion1 = nn.CrossEntropyLoss()\n",
        "criterion2 = nn.CrossEntropyLoss()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bSAqWUOL6bq"
      },
      "source": [
        "# Making sure that training is performed on GPU\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfQDztcxL6bq"
      },
      "source": [
        "num_epochs = 4\n",
        "\n",
        "def train_model(num_epochs, model, criterion1, criterion2, optimizer):\n",
        "    valid_loss_min = np.Inf\n",
        "    for epoch in range(1, num_epochs):\n",
        "        train_loss = 0.0\n",
        "        valid_loss = 0.0\n",
        "        # train the model #\n",
        "        model.train()\n",
        "        for batch_idx, batch in enumerate(train_dataloader.dataset):\n",
        "\n",
        "            # importing data and moving to GPU\n",
        "            image = batch['image'].to(device)\n",
        "            # print(image)\n",
        "            number = batch['number'].to(device)\n",
        "            # print(number)\n",
        "            # print(number.shape)\n",
        "            label1 = batch['label1'].to(device)\n",
        "            label2 = batch['label2'].to(device)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "            output=model(image, number)\n",
        "            label1_hat=output['label1']\n",
        "            label2_hat=output['label2']\n",
        "            # print(f' y: {label1}')\n",
        "\n",
        "            # print(f'y_hat:{label1_hat}') \n",
        "            #print(label1.shape) \n",
        "            #print(label1_hat.shape)\n",
        "\n",
        "                 \n",
        "            # calculate loss\n",
        "            loss1=criterion1(label1_hat, label1)\n",
        "            # print(f'label 2: {label2}')\n",
        "            # print(f'label2_hat: {label2_hat}')\n",
        "            # print(f'loss: {nn.CrossEntropyLoss(label2_hat, label2)}')\n",
        "            loss2=criterion2(label2_hat, label2)\n",
        "                \n",
        "            loss=loss1+loss2\n",
        "            \n",
        "            # back prop\n",
        "            loss.backward()\n",
        "            # grad\n",
        "            optimizer.step()\n",
        "            train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
        "            if batch_idx % 50 == 0:\n",
        "                print('Epoch %d, Batch %d loss: %.6f' %\n",
        "                  (epoch, batch_idx + 1, train_loss))\n",
        "        # validate the model #\n",
        "        model.eval()\n",
        "        for batch_idx, batch in enumerate(test_dataloader.dataset):\n",
        "            image = batch['image'].to(device)\n",
        "            # print(image)\n",
        "            number = batch['number'].to(device)\n",
        "            label1 = batch['label1'].to(device)\n",
        "            label2 = batch['label2'].to(device)\n",
        "            # print(label1)\n",
        "            \n",
        "            output= model(image, number)\n",
        "            label1_hat=output['label1']\n",
        "            label2_hat=output['label2']\n",
        "            # print(label1_hat) \n",
        "            # print(label1_hat.shape)\n",
        "          \n",
        "            # calculate loss\n",
        "            loss1=criterion1(label1_hat, label1)\n",
        "            loss2=criterion2(label2_hat, label2)\n",
        " \n",
        "            loss=loss1+loss2\n",
        "            valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss.data - valid_loss))\n",
        "        \n",
        "            # print training/validation statistics \n",
        "            print(f'Epoch: {epoch} \\tTraining Loss: {train_loss:.6f} \\tValidation Loss: {valid_loss:.6f}')\n",
        "        \n",
        "    # return trained model\n",
        "    return model"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sh2QU05vL6br",
        "outputId": "b588f5e1-c64c-464f-b854-baf7d7afa106"
      },
      "source": [
        "model_out = train_model(num_epochs, model, criterion1, criterion2, opt)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Batch 1 loss: 5.159516\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266365\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266363\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266351\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266360\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266359\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266377\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266360\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266340\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266344\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266322\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266394\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266380\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266385\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266365\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266355\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266335\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266346\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266366\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266366\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266347\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266325\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266323\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266341\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266320\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266311\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266343\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266368\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266348\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266352\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266346\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266323\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266307\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266294\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266293\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266292\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266308\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266294\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266317\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266306\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266318\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266315\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266328\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266335\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266330\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266312\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266304\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266288\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266279\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266286\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266278\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266269\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266251\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266312\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266337\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266319\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266321\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266299\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266291\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266285\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266265\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266264\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266255\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266239\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266219\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266212\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266190\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266202\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266185\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266164\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266154\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266142\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266132\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266111\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266102\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266095\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266094\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266099\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266106\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266103\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266083\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266062\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266064\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266062\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266065\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266062\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266048\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266041\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266028\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266019\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266018\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266033\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266028\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266019\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266021\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266040\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266017\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266033\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266022\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266012\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266025\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266011\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266024\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266070\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266067\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266061\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266040\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266050\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266051\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266087\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266115\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266137\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266131\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266123\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266102\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266083\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266062\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266126\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266132\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266118\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266125\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266104\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266109\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266107\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266109\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266127\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266105\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266087\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266071\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266049\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266035\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.266013\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265993\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265990\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265978\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265958\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265967\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265963\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265947\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265940\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265936\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265917\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265936\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265934\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265921\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265919\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265941\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265951\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265943\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265951\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265936\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265921\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265902\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265880\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265884\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265880\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265889\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265900\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265885\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265884\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265863\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265865\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265877\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265892\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265893\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265888\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265919\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265912\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265907\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265912\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265895\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265882\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265888\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265889\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265894\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265893\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265876\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265861\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265841\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265837\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265832\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265838\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265869\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265864\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265849\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265854\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265851\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265863\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265885\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265881\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265874\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265883\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265907\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265900\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265914\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265918\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265897\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265889\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265887\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265889\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265890\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265877\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265857\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265851\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265854\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265863\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265868\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265877\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265861\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265879\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265883\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265863\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265860\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265852\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265855\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265838\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265860\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265852\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265833\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265837\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265835\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265846\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265826\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265821\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265830\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265811\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265809\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265808\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265785\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265769\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265769\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265783\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265793\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265776\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265763\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265757\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265735\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265730\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265727\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265707\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265714\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265709\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265746\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265744\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265727\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265783\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265790\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265772\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265752\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265764\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265770\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265780\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265776\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265757\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265735\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265714\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265739\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265729\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265722\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265714\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265693\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265688\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265679\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265673\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265659\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265694\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265672\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265662\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265664\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265707\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265698\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265690\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265687\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265737\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265728\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265721\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265698\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265680\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265698\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265689\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265672\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265672\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265657\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265689\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265678\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265665\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265658\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265664\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265656\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265652\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265644\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265622\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265632\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265628\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265608\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265692\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265671\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265658\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265641\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265647\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265649\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265653\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265652\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265663\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265644\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265631\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265622\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265615\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265596\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265583\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265594\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265593\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265589\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265593\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265571\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265559\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265537\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265528\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265509\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265511\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265497\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265485\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265483\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265477\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265474\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265467\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265469\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265465\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265473\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265487\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265478\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265511\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265503\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265505\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265488\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265490\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265478\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265477\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265493\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265481\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265489\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265489\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265486\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265496\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265500\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265512\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265490\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265474\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265452\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265477\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265486\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265520\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265526\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265509\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265509\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265493\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265484\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265489\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265481\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265470\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265489\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265506\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265484\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265463\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265470\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265468\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265494\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265476\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265478\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265471\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265456\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265437\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265421\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265413\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265421\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265420\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265401\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265402\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265391\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265385\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265373\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265361\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265367\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265354\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265343\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265344\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265329\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265313\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265321\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265328\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265360\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265340\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265338\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265316\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265303\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265312\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265301\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265304\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265303\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265280\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265281\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265283\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265260\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265238\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265250\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265233\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265227\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265220\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265222\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265231\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265226\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265250\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265228\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265242\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265252\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265271\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265274\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265272\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265255\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265272\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265266\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265257\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265258\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265248\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265273\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265299\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265278\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265282\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265304\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265293\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265299\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265307\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265321\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265320\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265318\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265317\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265295\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265295\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265282\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265342\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265322\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265313\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265291\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265293\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265301\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265290\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265274\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265265\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265272\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265308\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265289\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265285\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265271\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265282\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265306\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265304\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265313\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265300\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265277\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265260\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265263\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265268\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265248\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265252\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265276\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265274\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265252\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265259\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265249\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265232\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265223\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265218\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265200\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265208\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265190\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265192\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265183\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265187\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265172\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265151\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265135\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265140\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265149\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265150\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265160\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265153\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265139\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265149\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265127\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265123\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265117\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265134\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265137\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265128\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265119\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265127\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265109\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265087\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265072\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265087\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265078\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265059\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265037\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265025\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265112\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265097\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265084\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265069\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265062\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265057\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265049\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265031\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265028\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265026\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265025\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265028\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265029\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265051\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265033\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265019\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265013\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265033\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265010\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264997\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264980\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264968\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264983\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264970\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264984\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264999\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265076\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265096\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265128\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265150\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265131\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265159\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265152\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265179\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265175\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265172\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265165\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265168\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265170\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265182\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265166\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265155\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265147\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265165\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265186\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265173\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265172\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265163\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265161\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265185\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265183\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265177\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265215\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265212\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265201\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265207\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265195\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265211\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265191\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265200\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265179\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265169\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265188\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265190\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265168\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265155\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265133\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265119\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265100\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265094\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265074\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265064\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265053\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265031\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265045\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265025\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265024\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265029\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265032\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265010\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265000\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264995\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265018\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265009\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264992\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264970\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264959\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264960\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264955\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264967\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264944\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264933\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264919\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264908\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264926\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264988\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264976\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264956\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264958\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264953\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264972\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265026\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265026\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265058\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265064\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265053\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265077\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265101\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265098\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265126\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265126\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265106\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265105\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265108\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265108\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265108\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265102\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265096\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265101\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265080\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265090\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265068\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265057\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265065\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265050\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265040\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265030\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265037\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265034\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265028\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265006\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264989\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264991\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264969\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264961\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264959\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264968\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264974\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265002\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264982\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264978\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264974\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265023\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265003\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264984\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265074\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265070\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265074\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265055\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265034\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265022\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265020\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265020\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.265002\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264997\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264985\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264993\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264979\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264985\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264973\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264979\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264976\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264956\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264942\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264965\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264975\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264990\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264986\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264991\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264984\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264974\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264967\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264953\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264980\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264968\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264971\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264963\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264943\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264940\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264953\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264934\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264916\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264930\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264911\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264927\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264925\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264950\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264967\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264948\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264936\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264944\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264953\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264952\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264942\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264922\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264929\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264908\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264891\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264870\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264853\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264854\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264863\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264863\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264857\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264853\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264847\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264828\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264807\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264785\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264776\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264777\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264768\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264777\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264767\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264767\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264778\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264760\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264774\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264797\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264811\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264806\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264792\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264806\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264799\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264826\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264827\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264845\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264870\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264875\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264856\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264838\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264850\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264855\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264856\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264875\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264868\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264862\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264863\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264845\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264825\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264820\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264821\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264810\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264802\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264790\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264790\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264774\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264754\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264756\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264737\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264750\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264748\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264748\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264743\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264752\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264752\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264772\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264763\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264750\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264728\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264741\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264752\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264743\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264738\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264723\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264706\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264708\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264688\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264673\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264691\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264694\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264705\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264723\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264723\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264721\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264706\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264697\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264709\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264713\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264699\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264682\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264667\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264646\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264650\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264648\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264641\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264643\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264626\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264610\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264654\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264649\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264647\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264643\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264624\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264628\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264621\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264601\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264596\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264574\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264576\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264553\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264628\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264605\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264592\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264571\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264596\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264599\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264607\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264610\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264605\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264583\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264677\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264655\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264663\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264665\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264669\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264651\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264657\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264661\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264639\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264632\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264626\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264609\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264594\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264600\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264602\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264607\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264585\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264572\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264576\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264564\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264569\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264549\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264540\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264518\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264540\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264545\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264523\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264504\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264486\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264510\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264514\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264515\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264499\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264485\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264490\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264470\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264453\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264434\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264423\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264420\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264402\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264381\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264396\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264379\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264379\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264365\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264390\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264383\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264397\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264399\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264398\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264411\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264406\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264407\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264413\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264418\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264473\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264461\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264465\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264443\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264436\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264442\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264430\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264434\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264446\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264426\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264419\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264420\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264412\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264418\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264414\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264405\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264423\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264402\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264399\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264407\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264484\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264494\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264472\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264470\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264490\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264479\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264492\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264492\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264493\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264475\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264456\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264462\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264499\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264503\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264510\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264509\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264503\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264483\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264513\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264507\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264516\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264494\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264497\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264490\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264479\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264471\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264464\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264444\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264506\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264486\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264485\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264464\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264441\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264455\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264446\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264426\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264437\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264421\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264427\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264442\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264468\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264451\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264439\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264422\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264436\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264428\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264418\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264409\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264389\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264372\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264353\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264333\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264326\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264325\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264339\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264328\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264318\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264321\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264328\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264308\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264311\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264294\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264302\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264307\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264295\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264273\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264266\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264243\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264279\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264276\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264268\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264252\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264247\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264228\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264216\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264207\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264217\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264195\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264184\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264183\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264165\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264171\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264174\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264171\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264210\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264219\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264216\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264226\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264220\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264213\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264201\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264210\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264192\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264179\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264168\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264176\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264155\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264152\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264144\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264145\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264155\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264132\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264117\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264096\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264120\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264104\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264089\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264082\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264067\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264069\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264052\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264050\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264039\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264016\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264002\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263985\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264029\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264011\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264017\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264006\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263990\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263994\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263976\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263979\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264023\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264058\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264060\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264053\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264062\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264058\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264064\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264054\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264057\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264036\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264048\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264045\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264028\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264051\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264042\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264030\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264022\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264019\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264026\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264017\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264016\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263999\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264017\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264027\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264017\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263998\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.264002\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263982\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263979\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263978\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263967\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263965\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263952\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263940\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263947\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263937\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263917\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263898\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263887\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263870\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263915\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263907\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263894\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263877\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263858\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263844\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263854\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263855\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263838\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263847\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263852\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263842\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263844\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263834\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263829\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263825\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263817\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263822\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263841\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263857\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263836\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263816\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263804\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263821\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263799\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263788\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263784\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263762\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263842\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263838\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263856\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263868\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263864\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263843\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263830\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263827\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263890\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263870\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263854\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263849\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263868\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263860\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263854\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263855\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263887\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263873\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263856\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263836\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263820\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263797\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263808\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263795\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263791\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263786\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263784\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263776\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263780\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263803\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263785\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263798\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263787\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263779\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263781\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263775\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263757\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263753\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263740\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263743\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263728\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263719\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263701\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263710\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263708\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263712\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263706\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263685\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263708\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263704\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263698\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263681\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263698\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263677\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263681\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263671\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263650\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263638\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263617\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263610\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263616\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263616\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263618\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263599\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263592\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263619\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263627\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263612\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263621\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263611\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263611\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263593\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263591\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263589\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263583\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263572\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263559\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263536\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263531\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263511\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263532\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263513\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263512\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263509\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263502\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263504\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263527\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263505\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263533\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263532\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263524\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263514\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263566\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263574\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263553\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263569\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263550\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263564\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263629\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263607\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263606\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263588\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263568\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263571\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263571\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263584\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263583\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263596\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263629\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263624\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263622\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263609\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263615\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263595\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263599\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263602\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263614\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263592\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263617\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263611\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263617\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263634\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263684\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263664\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263664\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263677\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263662\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263645\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263695\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263690\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263683\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263714\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263750\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263735\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263713\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263712\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263703\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263680\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263699\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263690\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263680\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263663\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263670\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263662\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263642\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263636\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263629\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263630\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263610\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263621\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263630\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263620\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263604\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263601\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263602\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263590\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263567\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263555\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263537\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263520\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263518\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263507\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263510\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263501\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263510\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263501\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263515\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263515\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263497\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263493\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263475\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263474\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263492\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263471\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263448\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263429\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263433\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263412\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263406\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263406\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263420\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263422\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263412\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263401\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263402\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263403\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263434\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263430\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263431\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263424\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263431\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263423\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263420\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263419\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263410\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263404\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263385\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263385\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263398\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263432\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263425\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263411\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263413\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263406\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263401\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263403\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263419\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263429\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263424\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263424\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263445\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263450\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263433\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263423\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263430\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263429\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263436\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263455\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263462\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263460\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263462\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263452\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263447\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263428\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263431\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263435\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263419\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263427\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263423\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263412\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263443\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263425\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263425\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263444\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263438\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263436\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263415\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263433\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263436\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263435\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263453\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263475\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263469\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263453\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263437\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263430\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263417\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263406\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263412\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263409\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263417\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263399\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263456\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263446\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263435\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263425\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263431\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263425\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263409\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263387\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263379\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263379\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263369\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263372\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263402\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263398\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263377\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263373\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263360\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263340\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263354\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263333\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263324\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263308\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263314\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263306\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263313\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263306\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263309\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263299\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263279\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263277\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263290\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263289\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263292\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263282\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263269\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263255\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263253\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263264\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263268\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263275\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263260\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263271\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263259\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263265\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263276\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263269\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263287\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263295\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263291\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263275\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263267\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263254\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263245\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263238\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263221\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263231\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263211\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263214\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263230\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263213\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263208\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263228\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263250\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263285\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263301\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263296\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263312\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263311\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263305\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263309\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263289\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263276\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263269\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263266\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263244\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263230\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263232\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263235\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263255\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263237\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263222\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263199\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263214\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263213\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263234\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263218\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263203\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263189\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263186\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263172\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263152\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263133\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263123\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263106\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263105\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263086\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263068\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263050\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263041\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263046\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263031\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263014\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262995\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263003\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263016\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263008\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263024\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263026\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263005\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263037\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263023\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263009\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263021\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263000\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262989\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262981\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262959\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262954\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263088\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263096\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263102\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263083\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263072\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263075\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263054\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263038\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263043\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263044\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263037\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263055\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263043\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263035\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263018\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263009\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.263005\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262984\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262973\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262977\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262997\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262981\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262969\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262959\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262952\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262946\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262924\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262932\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262972\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262986\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262983\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262965\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262962\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262966\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262945\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262941\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262928\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262931\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262934\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262922\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262913\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262935\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262933\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262925\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262935\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262925\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262923\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262920\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262908\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262928\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262913\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262923\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262953\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262959\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262944\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262952\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262935\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262915\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262905\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262894\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262894\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262891\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262899\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262908\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262930\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262930\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262921\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262918\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262913\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262904\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262882\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262862\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262850\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262839\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262850\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262873\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262874\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262862\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262848\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262846\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262841\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262830\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262810\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262791\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262771\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262766\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262745\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262754\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262742\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262734\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262723\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262706\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262713\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262709\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262693\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262712\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262711\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262715\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262710\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262705\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262692\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262691\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262680\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262682\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262680\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262672\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262656\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262651\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262631\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262632\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262645\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262642\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262692\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262688\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262687\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262688\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262677\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262680\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262659\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262680\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262679\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262670\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262658\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262645\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262658\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262637\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262647\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262632\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262643\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262634\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262625\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262624\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262607\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262606\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262617\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262618\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262623\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262617\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262629\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262637\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262618\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262616\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262625\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262623\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262765\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262749\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262764\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262770\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262826\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262819\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262811\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262791\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262784\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262780\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262765\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262773\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262762\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262742\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262721\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262702\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262687\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262687\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262751\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262749\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262761\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262742\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262730\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262738\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262720\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262720\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262703\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262705\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262716\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262725\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262761\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262744\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262736\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262740\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262751\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262750\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262767\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262764\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262763\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262741\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262759\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262747\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262761\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262770\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262774\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262756\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262749\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262741\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262737\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262737\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262727\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262734\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262762\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262776\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262790\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262770\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262766\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262769\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262780\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262767\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262773\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262759\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262779\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262831\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262812\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262811\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262845\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262861\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262851\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262848\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262844\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262830\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262825\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262821\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262805\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262839\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262930\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262919\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262898\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262891\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262881\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262865\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262873\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262861\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262868\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262876\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262874\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262862\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262840\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262826\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262808\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262811\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262802\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262784\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262764\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262769\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262767\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262758\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262762\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262778\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262761\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262753\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262753\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262750\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262744\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262738\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262740\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262724\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262702\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262685\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262665\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262644\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262649\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262637\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262616\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262610\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262621\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262609\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262601\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262585\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262575\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262593\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262603\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262600\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262617\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262607\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262611\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262631\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262646\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262641\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262651\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262655\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262638\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262631\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262612\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262628\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262639\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262625\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262615\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262609\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262596\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262587\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262600\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262583\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262577\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262581\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262561\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262558\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262542\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262546\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262538\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262528\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262537\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262551\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262545\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262529\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262518\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262512\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262495\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262473\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262455\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262482\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262464\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262452\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262442\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262438\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262432\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262461\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262459\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262467\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262445\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262446\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262435\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262426\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262413\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262405\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262393\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262386\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262441\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262462\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262455\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262436\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262414\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262393\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262387\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262370\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262378\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262375\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262369\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262365\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262355\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262347\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262339\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262328\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262323\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262313\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262292\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262304\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262297\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262292\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262321\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262305\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262298\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262304\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262419\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262398\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262388\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262370\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262392\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262447\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262440\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262419\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262428\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262438\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262423\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262432\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262443\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262444\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262433\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262413\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262405\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262392\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262437\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262421\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262432\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262427\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262422\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262404\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262431\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262448\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262441\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262488\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262487\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262469\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262458\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262465\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262460\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262451\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262440\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262428\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262416\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262419\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262436\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262416\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262430\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262437\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262470\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262472\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262463\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262443\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262424\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262407\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262411\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262412\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262421\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262418\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262427\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262426\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262411\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262403\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262422\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262432\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262414\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262393\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262577\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262556\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262557\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262554\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262541\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262547\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262565\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262555\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262536\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262532\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262537\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262518\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262522\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262536\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262550\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262540\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262538\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262518\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262514\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262515\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262506\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262487\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262500\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262481\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262460\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262444\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262456\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262457\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262462\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262459\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262465\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262465\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262470\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262499\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262511\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262523\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262505\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262496\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262500\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262501\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262496\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262489\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262471\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262466\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262493\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262475\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262454\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262447\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262432\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262450\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262434\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262415\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262399\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262404\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262400\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262381\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262374\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262357\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262368\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262353\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262347\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262347\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262356\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262338\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262339\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262330\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262335\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262329\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262357\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262339\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262320\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262324\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262317\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262302\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262291\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262298\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262317\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262316\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262311\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262325\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262304\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262284\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262267\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262254\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262248\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262256\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262268\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262272\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262251\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262260\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262307\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262326\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262324\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262325\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262304\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262283\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262283\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262270\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262262\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262251\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262247\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262246\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262239\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262243\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262233\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262234\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262233\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262233\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262211\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262195\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262190\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262168\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262179\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262194\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262182\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262191\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262192\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262212\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262348\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262357\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262338\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262326\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262317\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262321\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262324\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262330\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262317\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262300\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262303\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262308\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262343\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262349\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262374\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262374\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262370\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262370\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262363\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262359\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262400\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262401\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262400\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262396\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262393\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262373\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262371\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262354\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262332\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262314\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262296\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262297\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262298\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262292\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262298\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262291\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262290\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262281\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262278\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262283\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262274\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262271\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262253\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262324\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262311\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262301\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262282\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262283\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262288\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262267\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262262\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262253\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262274\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262268\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262259\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262238\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262216\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262215\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262211\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262218\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262203\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262187\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262200\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262223\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262210\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262200\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262192\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262173\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262178\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262159\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262170\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262152\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262131\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262150\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262128\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262110\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262208\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262208\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262219\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262217\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262214\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262229\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262209\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262187\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262185\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262176\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262184\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262178\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262161\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262142\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262121\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262113\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262115\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262116\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262097\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262079\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262083\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262071\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262087\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262076\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262063\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262044\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262031\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262026\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262047\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262028\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262018\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.262002\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261995\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261984\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261981\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261972\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261958\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261938\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261918\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261923\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261902\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261890\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261879\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261870\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261853\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261847\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261827\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261810\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261794\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261803\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261796\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261793\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261810\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261807\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261786\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261788\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261793\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261783\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261795\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261786\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261778\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261756\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261746\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261727\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261713\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261714\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261693\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261679\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261666\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261671\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261720\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261730\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261767\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261755\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261759\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261739\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261723\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261706\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261693\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261690\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261701\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261699\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261705\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261694\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261688\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261699\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261703\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261693\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261690\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261696\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261691\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261676\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261664\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261691\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261684\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261664\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261667\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261716\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261733\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261732\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261761\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261778\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261801\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261805\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261794\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261804\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261800\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261778\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261759\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261764\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261752\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261754\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261749\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261737\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261739\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261723\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261721\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261708\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261696\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261698\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261689\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261668\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261646\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261663\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261656\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261651\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261703\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261693\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261687\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261681\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261687\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261688\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261742\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261722\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261793\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261796\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261788\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261780\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261771\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261783\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261787\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261773\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261755\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261738\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261723\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261724\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261711\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261689\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261671\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261653\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261642\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261651\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261636\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261624\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261641\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261643\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261633\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261661\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261687\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261683\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261666\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261650\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261662\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261649\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261669\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261647\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261629\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261632\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261613\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261620\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261619\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261607\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261627\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261609\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261614\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261642\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261626\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261622\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261626\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261639\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261647\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261648\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261640\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261629\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261608\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261590\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261620\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261602\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261603\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261593\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261598\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261592\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261572\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261576\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261571\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261586\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261575\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261581\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261581\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261577\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261574\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261580\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261605\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261625\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261607\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261586\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261603\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261581\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261601\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261584\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261572\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261569\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261578\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261562\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261551\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261545\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261537\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261595\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261584\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261575\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261567\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261554\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261683\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261665\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261652\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261649\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261632\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261613\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261603\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261631\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261622\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261625\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261618\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261597\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261578\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261581\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261572\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261580\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261570\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261574\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261552\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261536\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261526\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261525\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261504\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261492\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261481\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261469\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261488\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261484\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261464\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261449\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261438\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261439\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261450\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261429\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261409\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261420\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261417\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261417\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261424\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261438\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261428\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261450\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261435\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261453\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261447\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261425\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261408\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261502\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261494\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261525\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261503\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261504\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261582\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261575\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261562\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261563\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261555\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261533\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261564\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261554\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261619\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261615\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261648\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261631\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261618\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261614\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261613\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261636\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261627\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261624\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261608\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261608\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261596\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261575\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261557\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261555\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261547\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261553\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261551\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261543\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261521\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261510\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261494\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261477\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261469\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261498\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261485\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261473\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261461\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261469\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261455\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261491\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261506\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261522\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261520\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261516\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261507\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261489\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261470\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261455\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261468\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261486\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261484\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261480\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261483\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261501\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261502\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261508\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261487\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261480\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261484\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261475\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261477\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261462\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261440\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261436\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261429\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261407\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261393\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261371\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261366\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261344\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261341\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261338\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261335\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261339\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261328\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261340\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261349\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261342\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261322\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261300\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261333\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261441\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261423\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261421\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261414\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261413\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261419\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261400\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261388\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261413\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261408\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261408\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261387\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261367\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261358\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261337\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261343\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261345\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261338\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261322\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261306\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261297\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261302\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261294\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261279\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261263\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261270\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261248\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261255\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261234\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261224\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261207\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261204\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261207\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261199\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261211\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261189\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261181\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261176\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261178\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261197\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261177\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261205\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261184\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261184\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261177\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261185\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261179\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261206\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261279\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261259\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261275\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261265\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261256\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261256\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261241\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261228\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261211\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261225\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261214\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261215\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261199\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261194\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261172\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261173\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261180\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261181\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261190\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261175\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261215\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261207\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261214\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261235\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261228\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261214\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261192\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261201\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261203\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261283\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261262\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261249\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261248\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261242\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261226\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261218\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261206\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261229\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261220\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261212\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261209\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261189\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261176\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261176\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261166\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261160\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261169\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261166\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261146\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261138\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261122\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261126\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261108\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261152\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261153\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261143\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261127\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261127\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261137\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261151\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261133\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261122\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261112\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261113\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261096\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261087\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261083\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261099\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261085\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261079\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261074\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261062\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261064\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261055\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261035\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261026\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261016\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261019\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261010\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261028\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261040\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261071\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261053\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261056\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261046\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261070\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261181\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261201\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261179\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261175\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261158\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261157\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261137\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261138\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261118\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261104\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261104\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261104\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261098\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261109\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261106\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261084\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261071\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261088\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261078\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261065\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261043\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261095\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261084\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261142\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261124\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261117\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261115\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261132\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261126\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261141\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261135\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261133\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261115\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261097\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261099\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261096\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261082\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261071\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261057\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261077\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261085\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261099\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261088\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261076\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261070\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261063\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261073\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261054\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261044\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261049\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261053\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261044\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261027\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261014\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.261001\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260995\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260980\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260971\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260951\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260987\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260977\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260967\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260956\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260941\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260926\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260941\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260932\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260936\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260938\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260932\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260926\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260928\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260922\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260908\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260900\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260906\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260909\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260894\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260900\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260895\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260877\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260880\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260889\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260873\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260863\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260879\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260891\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260910\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260905\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260918\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260906\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260898\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260896\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260877\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260872\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260873\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260866\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260859\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260850\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260878\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260875\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260860\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260839\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260826\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260824\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260853\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260839\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260817\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260805\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260787\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260820\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260811\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260801\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260810\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260789\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260787\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260798\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260786\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260768\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260781\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260795\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260774\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260789\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260769\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260749\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260730\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260717\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260696\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260692\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260679\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260677\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260657\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260645\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260626\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260616\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260605\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260594\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260603\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260583\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260561\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260554\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260538\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260518\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260560\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260549\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260528\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260534\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260533\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260534\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260531\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260564\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260577\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260573\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260607\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260625\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260623\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260603\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260600\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260633\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260625\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260616\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260639\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260643\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260653\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260631\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260625\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260617\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260646\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260651\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260643\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260633\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260641\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260637\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260631\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260628\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260648\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260638\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260677\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260703\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260687\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260679\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260698\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260695\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260687\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260671\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260681\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260669\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260672\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260677\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260690\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260685\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260667\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260658\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260679\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260678\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260674\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260683\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260666\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260705\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260713\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260731\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260726\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260706\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260685\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260694\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260688\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260673\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260670\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260651\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260635\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260614\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260623\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260622\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260628\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260609\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260613\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260602\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260585\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260569\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260558\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260555\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260618\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260621\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260604\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260611\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260617\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260595\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260603\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260608\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260648\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260654\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260669\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260651\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260642\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260651\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260634\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260627\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260617\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260628\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260609\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260615\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260594\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260575\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260553\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260543\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260539\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260531\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260516\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260515\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260504\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260500\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260584\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260564\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260555\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260536\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260538\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260524\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260525\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260506\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260496\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260490\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260486\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260481\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260486\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260472\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260526\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260521\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260540\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260534\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260561\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260544\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260559\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260550\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260546\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260526\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260520\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260509\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260492\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260491\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260512\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260501\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260507\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260490\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260486\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260471\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260464\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260459\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260449\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260439\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260425\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260413\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260419\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260422\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260404\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260421\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260409\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260393\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260377\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260370\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260383\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260362\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260352\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260362\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260366\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260347\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260341\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260335\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260317\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260303\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260302\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260314\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260294\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260283\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260275\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260285\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260282\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260263\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260287\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260276\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260275\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260262\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260255\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260240\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260222\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260217\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260228\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260226\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260220\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260235\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260223\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260217\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260199\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260185\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260184\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260169\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260174\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260156\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260146\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260144\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260295\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260291\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260280\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260281\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260287\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260286\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260286\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260300\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260321\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260312\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260300\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260290\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260285\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260273\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260256\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260245\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260247\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260232\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260220\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260212\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260205\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260188\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260186\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260201\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260185\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260194\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260180\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260177\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260178\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260177\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260156\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260143\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260142\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260123\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260144\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260126\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260117\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260116\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260117\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260120\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260111\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260108\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260087\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260078\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260067\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260087\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260099\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260098\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260082\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260070\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260081\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260081\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260091\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260100\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260088\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260082\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260077\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260072\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260060\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260042\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260043\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260042\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260171\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260160\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260144\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260148\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260148\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260165\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260173\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260170\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260175\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260198\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260207\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260195\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260242\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260226\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260216\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260213\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260192\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260173\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260152\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260130\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260131\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260132\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260140\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260148\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260136\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260115\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260119\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260101\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260204\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260193\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260175\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260156\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260151\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260129\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260187\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260179\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260184\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260182\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260188\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260178\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260172\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260185\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260170\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260167\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260157\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260164\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260151\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260172\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260158\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260171\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260166\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260145\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260147\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260149\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260142\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260148\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260137\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260146\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260140\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260131\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260112\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260103\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260093\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260092\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260073\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260095\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260090\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260081\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260066\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260047\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260027\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260030\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260049\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260031\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260056\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260043\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260032\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260028\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260022\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260013\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260012\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260002\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260009\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259997\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259983\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260003\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260025\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260026\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260013\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260006\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259985\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259964\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260000\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260001\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259980\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259969\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259971\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259958\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259956\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259955\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259967\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259956\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259936\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259920\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259918\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259910\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259903\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259886\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259869\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259892\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259894\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259890\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259885\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259883\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259911\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259892\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259889\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259885\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259878\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259868\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259866\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259868\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259880\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259877\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259864\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259843\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259835\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259837\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259870\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260041\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260022\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260030\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.260010\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259997\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259977\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259965\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259958\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259938\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259939\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259922\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259904\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259904\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259899\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259902\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259882\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259877\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259858\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259858\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259849\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259832\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259823\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259829\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259820\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259827\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259824\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259828\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259810\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259828\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259839\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259840\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259843\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259865\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259856\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259849\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259864\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259856\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259866\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259881\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259861\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259854\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259852\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259881\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259916\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259912\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259913\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259905\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259890\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259903\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259953\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259942\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259941\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259946\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259936\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259919\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259926\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259907\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259918\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259912\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259894\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259914\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259899\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259905\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259922\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259909\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259905\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259916\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259923\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259911\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259927\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259931\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259934\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259936\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259917\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259908\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259893\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259893\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259886\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259894\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259875\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259873\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259883\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259887\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259879\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259903\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259883\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259863\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259863\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259866\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259862\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259855\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259872\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259896\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259887\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259925\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259936\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259917\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259939\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259939\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259922\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259934\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259937\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259929\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259934\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259946\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259933\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259929\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259933\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259915\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259927\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259919\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259911\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259931\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259937\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259918\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259904\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259903\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259898\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259880\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259870\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259871\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259888\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259879\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259862\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259854\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259843\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259851\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259848\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259844\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259863\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259846\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259828\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259820\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259805\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259807\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259808\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259803\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259820\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259819\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259835\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259815\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259812\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259805\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259791\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259796\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259789\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259780\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259772\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259754\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259736\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259714\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259702\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259701\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259693\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259720\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259712\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259693\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259689\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259674\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259662\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259668\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259660\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259655\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259644\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259646\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259649\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259645\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259665\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259670\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259651\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259631\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259622\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259600\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259599\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259602\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259611\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259602\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259585\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259583\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259587\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259567\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259572\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259562\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259541\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259540\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259552\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259542\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259532\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259529\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259525\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259509\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259505\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259487\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259469\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259480\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259476\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259460\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259464\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259472\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259453\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259461\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259446\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259430\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259427\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259422\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259431\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259445\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259437\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259421\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259402\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259397\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259379\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259358\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259341\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259341\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259330\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259343\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259341\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259334\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259330\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259318\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259303\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259305\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259300\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259290\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259285\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259266\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259258\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259263\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259261\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259269\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259292\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259273\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259251\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259245\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259248\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259238\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259232\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259221\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259218\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259197\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259184\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259169\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259157\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259148\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259158\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259148\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259163\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259158\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259139\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259121\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259103\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259083\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259073\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259063\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259065\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259055\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259053\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259033\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259015\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.259006\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258984\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258991\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258981\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258962\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258947\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258942\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258943\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258958\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258941\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258934\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258941\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258947\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258944\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258924\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258903\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258911\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258889\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258869\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258871\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258901\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258887\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258873\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258852\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258845\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258847\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258846\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258826\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258820\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258803\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258785\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258771\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258769\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258756\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258738\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258725\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258705\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258711\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258703\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258694\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258699\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258681\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258676\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258664\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258646\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258656\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258651\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258639\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258672\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258669\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258679\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258673\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258655\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258658\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258642\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258633\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258618\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258648\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258665\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258658\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258652\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258641\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258621\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258608\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258587\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258578\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258581\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258575\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258557\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258545\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258538\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258536\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258523\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258514\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258497\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258476\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258483\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258483\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258494\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258484\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258524\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258515\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258504\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258497\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258506\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258502\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258502\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258487\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258481\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258469\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258476\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258470\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258461\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258453\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258442\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258451\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258461\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258449\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258442\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258438\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258429\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258431\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258482\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258476\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258583\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258595\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258599\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258611\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258603\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258608\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258608\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258631\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258641\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258620\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258627\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258607\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258594\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258618\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258597\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258611\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258605\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258609\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258601\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258589\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258568\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258548\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258542\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258544\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258539\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258519\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258515\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258498\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258509\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258505\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258490\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258486\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258494\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258579\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258605\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258605\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258651\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258644\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258658\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258652\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258647\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258654\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258643\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258639\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258620\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258626\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258643\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258690\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258681\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258669\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258655\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258650\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258628\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258636\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258644\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258623\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258603\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258587\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258585\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258574\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258579\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258565\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258548\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258528\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258529\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258516\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258507\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258514\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258508\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258491\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258508\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258500\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258485\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258463\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258466\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258474\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258471\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258468\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258478\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258477\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258458\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258454\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258437\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258440\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258419\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258423\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258407\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258408\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258389\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258371\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258401\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258383\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258378\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258375\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258370\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258350\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258340\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258321\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258316\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258318\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258310\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258302\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258315\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258313\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258300\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258279\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258267\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258249\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258250\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258232\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258229\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258213\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258215\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258203\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258195\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258182\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258162\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258162\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258156\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258136\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258121\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258112\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258126\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258110\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258103\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258084\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258069\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258052\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258033\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258017\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258000\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257991\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258003\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258013\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.258006\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257997\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257977\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257994\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257974\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257973\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257954\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257964\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257960\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257946\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257928\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257929\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257930\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257915\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257901\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257900\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257899\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257902\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257884\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257869\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257853\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257841\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257837\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257816\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257824\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257805\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257804\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257788\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257804\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257801\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257789\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257801\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257794\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257797\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257790\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257779\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257778\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257761\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257740\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257747\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257745\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257736\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257725\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257705\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257720\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257699\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257702\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257693\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257700\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257707\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257692\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257705\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257706\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257714\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257709\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257695\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257689\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257698\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257689\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257681\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257676\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257703\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257716\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257698\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257691\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257680\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257660\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257646\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257627\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257617\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257596\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257605\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257588\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257580\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257562\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257568\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257548\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257566\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257568\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257591\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257596\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257605\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257624\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257625\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257625\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257607\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257598\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257580\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257562\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257587\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257576\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257556\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257552\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257538\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257518\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257507\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257517\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257522\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257513\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257497\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257489\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257472\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257455\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257444\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257423\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257419\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257410\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257398\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257393\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257376\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257370\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257360\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257354\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257337\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257320\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257320\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257314\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257337\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257322\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257312\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257312\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257297\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257287\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257266\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257278\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257260\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257257\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257239\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257218\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257204\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257200\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257179\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257158\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257151\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257149\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257147\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257141\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257144\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257134\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257135\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257124\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257128\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257122\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257123\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257132\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257114\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257096\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257076\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257059\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257048\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257035\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257025\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257040\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257046\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257036\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257015\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.257002\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256999\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256990\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256989\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256985\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256966\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256971\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256976\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256962\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256958\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256946\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256925\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256920\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256917\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256915\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256896\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256874\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256858\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256852\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256831\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256819\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256832\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256850\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256830\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256821\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256822\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256820\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256799\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256808\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256803\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256795\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256792\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256783\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256773\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256760\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256752\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256735\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256732\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256711\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256691\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256679\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256658\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256637\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256639\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256621\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256605\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256584\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256582\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256626\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256648\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256909\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256899\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256895\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256912\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256906\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256887\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256870\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256849\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256839\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256855\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256836\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256833\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256818\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256824\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256803\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256784\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256781\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256796\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256814\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256798\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256786\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256791\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256794\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256776\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256772\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256780\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256778\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256763\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256749\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256752\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256751\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256752\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256737\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256722\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256726\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256752\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256763\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256765\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256753\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256743\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256743\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256723\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256702\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256699\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256696\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256730\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256721\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256706\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256705\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256702\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256684\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256663\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256658\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256658\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256643\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256648\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256652\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256638\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256659\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256647\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256652\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256632\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256619\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256624\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256630\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256618\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256626\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256622\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256614\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256609\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256637\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256618\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256620\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256603\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256596\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256578\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256604\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256592\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256586\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256590\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256588\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256571\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256584\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256593\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256574\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256578\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256572\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256552\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256556\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256587\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256578\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256579\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256560\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256558\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256557\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256544\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256532\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256529\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256522\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256504\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256517\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256500\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256480\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256477\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256469\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256448\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256455\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256443\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256458\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256441\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256429\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256434\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256418\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256418\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256399\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256384\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256378\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256368\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256355\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256342\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256325\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256307\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256289\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256279\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256262\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256276\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256268\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256271\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256285\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256276\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256277\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256274\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256274\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256262\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256255\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256246\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256229\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256227\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256217\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256199\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256200\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256185\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256174\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256154\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256147\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256137\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256138\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256124\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256128\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256128\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256111\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256115\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256120\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256114\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256105\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256111\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256106\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256084\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256071\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256056\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256044\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256036\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256029\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256034\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256026\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.256005\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255985\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255973\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255985\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255973\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255974\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255981\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255968\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255971\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255966\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255949\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255932\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255916\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255906\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255951\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255952\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255953\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255934\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255947\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255927\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255929\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255933\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255937\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255928\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255909\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255888\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255868\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255858\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255856\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255840\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255820\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255811\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255794\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255786\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255789\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255796\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255779\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255759\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255744\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255736\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255719\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255708\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255691\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255692\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255691\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255714\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255710\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255718\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255716\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255719\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255738\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255720\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255758\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255748\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255745\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255746\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255756\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255747\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255749\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255736\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255727\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255724\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255713\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255709\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255688\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255684\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255686\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255698\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255705\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255725\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255706\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255698\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255696\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255683\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255674\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255678\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255670\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255651\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255663\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255656\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255651\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255657\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255638\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255641\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255646\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255627\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255607\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255599\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255610\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255621\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255615\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255624\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255639\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255630\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255618\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255612\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255598\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255610\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255608\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255609\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255597\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255577\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255556\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255541\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255530\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255547\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255559\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255545\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255526\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255504\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255512\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255496\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255492\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255482\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255465\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255455\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255434\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255422\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255413\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255401\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255414\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255407\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255410\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255428\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255421\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255415\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255410\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255430\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255430\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255416\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255409\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255415\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255424\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255406\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255411\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255392\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255371\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255351\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255335\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255330\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255339\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255335\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255314\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255297\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255311\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255345\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255356\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255354\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255358\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255354\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255351\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255349\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255347\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255326\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255317\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255310\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255317\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255297\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255284\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255284\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255288\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255268\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255257\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255260\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255254\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255235\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255258\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255240\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255239\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255219\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255203\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255207\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255201\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255202\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255185\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255184\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255193\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255190\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255180\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255179\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255173\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255171\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255177\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255185\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255203\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255182\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255175\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255192\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255177\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255157\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255157\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255167\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255176\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255156\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255155\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255150\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255146\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255127\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255130\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255140\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255139\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255120\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255115\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255116\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255119\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255105\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255084\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255080\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255059\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255050\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255039\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255023\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.255004\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254986\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254977\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254978\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254976\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254966\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254975\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254965\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254956\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254946\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254926\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254909\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254888\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254881\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254881\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254875\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254870\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254863\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254867\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254871\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254853\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254859\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254838\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254849\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254846\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254838\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254841\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254840\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254831\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254820\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254813\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254804\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254796\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254800\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254795\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254807\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254803\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254782\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254787\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254779\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254759\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254756\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254753\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254732\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254755\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254738\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254728\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254721\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254739\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254751\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254748\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254727\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254717\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254701\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254718\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254699\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254704\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254692\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254711\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254727\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254709\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254698\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254685\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254695\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254689\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254674\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254657\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254637\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254621\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254614\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254602\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254582\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254597\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254610\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254601\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254604\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254607\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254602\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254611\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254622\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254620\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254609\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254589\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254584\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254565\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254573\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254556\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254535\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254527\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254508\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254490\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254477\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254491\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254488\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254483\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254492\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254495\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254482\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254480\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254494\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254509\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254518\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254497\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254518\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254506\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254513\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254496\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254494\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254486\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254479\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254500\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254486\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254471\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254451\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254470\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254458\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254448\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254436\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254415\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254405\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254390\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254381\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254377\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254382\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254386\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254389\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254383\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254387\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254384\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254378\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254377\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254366\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254353\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254356\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254336\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254339\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254348\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254376\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254358\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254353\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254333\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254314\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254294\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254296\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254300\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254293\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254292\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254303\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254302\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254304\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254314\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254301\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254306\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254297\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254279\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254287\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254281\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254285\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254288\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254267\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254335\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254321\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254306\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254313\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254304\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254283\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254285\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254288\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254290\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254272\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254274\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254269\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254268\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254275\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254270\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254275\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254283\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254264\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254256\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254262\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254257\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254277\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254274\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254254\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254254\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254238\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254222\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254209\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254188\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254202\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254250\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254243\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254236\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254233\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254249\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254246\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254242\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254227\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254228\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254244\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254274\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254276\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254272\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254273\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254270\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254263\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254248\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254243\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254241\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254248\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254232\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254236\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254229\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254215\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254211\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254216\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254202\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254203\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254185\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254182\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254169\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254163\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254181\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254182\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254164\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254159\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254156\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254140\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254164\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254153\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254174\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254156\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254158\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254144\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254126\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254132\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254135\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254120\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254107\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254115\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254113\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254109\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254122\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254103\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254089\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254105\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254103\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254108\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254113\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254141\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254124\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254112\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254101\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254094\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254106\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254085\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254076\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254074\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254077\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254086\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254076\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254065\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254057\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254044\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254091\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254076\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254125\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254185\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254174\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254207\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254203\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254190\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254190\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254195\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254181\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254176\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254177\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254180\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254173\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254233\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254283\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254286\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254276\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254272\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254255\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254243\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254252\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254308\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254290\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254270\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254268\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254284\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254387\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254375\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254381\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254363\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254342\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254346\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254326\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254314\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254300\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254292\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254286\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254313\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254298\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254303\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254335\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254334\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254326\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254326\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254307\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254310\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254295\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254327\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254322\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254321\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254316\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254307\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254286\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254283\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254280\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254275\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254267\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254247\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254230\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254219\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254230\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254213\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254204\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254197\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254191\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254181\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254175\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254154\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254138\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254127\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254127\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254150\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254147\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254164\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254145\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254135\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254114\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254098\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254082\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254071\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254065\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254050\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254052\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254063\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254045\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254046\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254032\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254042\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254034\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254040\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.254019\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253999\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253989\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253971\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253950\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253960\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253965\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253944\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253926\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253935\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253915\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253923\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253927\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253910\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253903\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253896\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253893\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253896\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253882\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253874\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253880\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253862\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253856\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253837\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253852\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253838\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253857\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253852\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253867\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253857\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253856\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253835\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253816\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253809\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253814\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253798\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253790\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253770\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253768\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253764\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253757\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253745\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253745\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253762\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253754\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253738\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253737\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253743\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253722\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253704\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253694\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253682\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253706\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253703\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253684\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253684\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253667\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253661\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253657\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253658\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253659\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253666\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253676\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253659\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253654\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253649\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253651\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253637\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253646\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253651\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253685\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253679\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253672\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253681\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253677\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253656\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253656\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253650\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253654\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253705\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253692\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253681\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253674\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253670\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253650\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253630\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253614\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253620\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253603\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253593\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253600\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253588\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253570\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253561\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253542\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253523\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253512\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253514\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253512\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253505\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253503\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253487\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253482\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253481\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253468\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253449\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253434\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253435\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253440\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253433\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253430\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253420\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253415\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253397\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253391\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253371\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253379\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253382\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253383\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253401\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253382\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253374\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253357\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253336\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253318\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253314\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253308\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253301\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253299\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253281\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253269\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253307\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253297\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253294\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253274\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253305\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253305\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253300\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253287\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253292\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253276\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253278\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253266\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253321\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253318\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253308\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253288\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253276\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253260\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253241\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253227\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253218\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253228\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253219\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253213\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253206\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253185\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253171\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253150\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253153\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253160\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253143\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253137\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253135\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253118\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253130\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253127\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253117\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253114\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253114\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253094\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253115\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253110\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253126\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253115\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253103\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253105\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253086\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253098\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253078\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253070\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253067\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253046\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253038\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253051\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253031\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253021\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253034\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253029\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253021\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253013\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253004\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252999\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252998\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252977\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252957\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252944\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252948\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252939\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252938\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252918\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252910\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252890\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252872\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252883\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252893\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252997\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253013\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253016\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253028\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253090\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253096\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253120\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253099\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253125\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253122\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253120\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253122\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253118\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253109\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253089\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253099\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253097\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253098\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253104\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253094\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253086\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253101\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253085\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253106\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253109\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253089\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253081\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253078\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253081\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253074\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253072\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253079\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253059\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253039\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253040\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253039\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253026\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253043\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253037\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.253018\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252998\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252987\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252983\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252970\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252970\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252951\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252933\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252934\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252926\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252905\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252908\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252889\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252873\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252870\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252863\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252842\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252842\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252839\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252843\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252832\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252813\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252822\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252821\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252814\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252813\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252795\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252774\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252759\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252739\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252736\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252715\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252710\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252723\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252711\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252702\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252716\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252698\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252694\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252674\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252654\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252640\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252624\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252623\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252611\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252600\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252592\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252579\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252567\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252554\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252551\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252549\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252546\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252527\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252524\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252531\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252528\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252532\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252519\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252499\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252489\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252474\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252461\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252447\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252430\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252415\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252424\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252422\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252413\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252414\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252401\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252403\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252389\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252394\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252374\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252367\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252359\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252339\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252337\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252331\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252312\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252299\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252282\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252276\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252270\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252252\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252250\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252242\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252244\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252234\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252227\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252226\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252227\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252221\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252222\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252225\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252210\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252210\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252206\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252200\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252201\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252211\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252190\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252173\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252153\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252159\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252148\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252145\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252130\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252110\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252102\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252102\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252109\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252088\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252067\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252066\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252049\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252033\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252041\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252042\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252041\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252029\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252043\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252024\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252033\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252034\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252032\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252032\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252020\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252013\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252028\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252023\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.252002\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251991\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251987\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251970\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251970\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251961\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251949\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251945\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251944\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251929\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251932\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251928\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251915\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251909\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251889\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251891\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251874\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251879\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251868\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251862\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251848\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251849\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251843\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251824\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251820\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251803\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251787\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251787\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251886\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251868\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251849\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251833\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251817\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251802\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251790\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251802\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251806\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251800\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251780\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251760\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251761\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251745\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251724\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251718\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251732\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251722\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251711\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251700\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251690\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251671\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251672\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251653\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251634\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251615\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251604\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251590\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251576\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251558\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251557\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251560\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251548\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251528\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251519\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251521\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251506\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251486\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251485\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251464\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251463\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251464\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251461\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251444\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251445\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251456\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251449\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251430\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251420\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251416\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251402\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251397\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251387\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251385\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251366\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251360\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251354\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251333\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251316\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251318\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251309\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251305\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251300\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251281\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251266\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251262\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251245\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251239\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251227\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251209\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251199\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251182\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251161\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251142\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251125\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251105\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251089\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251070\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251066\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251066\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251046\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251029\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251017\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.251005\n",
            "Epoch: 3 \tTraining Loss: 1.281497 \tValidation Loss: 1.250991\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnlME30aC8VY"
      },
      "source": [
        "\n",
        "prediction = model(train_dataloader.dataset[0]['image'], train_dataloader.dataset[0]['number'])"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDzFIllUQv-K",
        "outputId": "d74eaa4b-4870-4a71-c5f6-5c966b0d3fa6"
      },
      "source": [
        "prediction"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label1': tensor([[-4.1065, -3.1094, -4.0920,  2.1197, -1.9170,  9.1153,  2.3200, -0.6874,\n",
              "           0.6051,  1.4400]], grad_fn=<AddmmBackward>),\n",
              " 'label2': tensor([[ -2.2587,   8.4145,  13.2392,  18.0544,  19.8932,  21.4266,  23.9472,\n",
              "           22.4666,  24.1001,  20.7890,  17.1193,   6.7382,  -4.5856, -10.9834,\n",
              "          -17.0472, -27.6351, -36.2526, -45.4224, -52.0836]],\n",
              "        grad_fn=<AddmmBackward>)}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKBepxipQy3P",
        "outputId": "fbf07f2a-5644-46ce-d437-00063d372f7d"
      },
      "source": [
        "np.argmax(prediction['label1'].detach().numpy())"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRAMfRtaRBp9",
        "outputId": "752fe53f-9fa9-4af3-93d0-c94b03534e6e"
      },
      "source": [
        "np.argmax(prediction['label2'].detach().numpy())"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ie0hWRAZRchw"
      },
      "source": [
        "prediction = model(test_dataloader.dataset[0]['image'], train_dataloader.dataset[0]['number'])"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oR63lQrAUB49",
        "outputId": "3320af57-4ee0-40c4-9d6e-8d43a9bb850d"
      },
      "source": [
        "print(np.argmax(prediction['label1'].detach().numpy()), test_dataloader.dataset[0]['label1'].detach().numpy()[0])\n",
        "print(np.argmax(prediction['label2'].detach().numpy()), test_dataloader.dataset[0]['label2'].detach().numpy()[0])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5 5\n",
            "8 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twWKlLAhbD0P"
      },
      "source": [
        "mnist_label1 = []\n",
        "add_label2 = []\n",
        "\n",
        "for batch in dataset:\n",
        "  image = batch['image'].to(device)\n",
        "  number = batch['number'].to(device)\n",
        "  label1 = batch['label1'].to(device)\n",
        "  label2 = batch['label2'].to(device)\n",
        "\n",
        "\n",
        "  prediction = model(image, number)\n",
        "  #print(f\"predicted label = {np.argmax(prediction['label1'].detach().numpy())}\")\n",
        "  #print(f\"target label = {label1.detach().numpy()[0]}\")\n",
        "  if np.argmax(prediction['label1'].detach().numpy()) == label1.detach().numpy()[0]:\n",
        "    mnist_label1.append(True)\n",
        "  if np.argmax(prediction['label2'].detach().numpy()) == label2.detach().numpy()[0]:\n",
        "      add_label2.append(True)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wxl_dIyFk5Lz",
        "outputId": "5065049b-0ed4-47eb-a7eb-b2d847c916cf"
      },
      "source": [
        "print(f'Accuracy of Mnist dataset on training: {(len(mnist_label1)/len(mnist))*100}')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Mnist dataset on training: 98.16333333333334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22A0usDcnraG",
        "outputId": "d85c0cca-abd6-495f-84dd-81a41ecdd74f"
      },
      "source": [
        "print(f'Accuracy of Mnist dataset on training: {(len(add_label2)/len(mnist))*100}')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Mnist dataset on training: 51.575\n"
          ]
        }
      ]
    }
  ]
}